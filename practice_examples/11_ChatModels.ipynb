{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b0c23f3c",
      "metadata": {
        "id": "b0c23f3c"
      },
      "source": [
        "## Chat-style GPT model experiments\n",
        "\n",
        "### Inference\n",
        "- Load the model, set up correct inference parameters.\n",
        "- Write basic functions for creating system, user and assistant prompts.\n",
        "- Write a class which facilitates communication with a model. Add a function to call when it is the user's turn. This function should take inputs from the user and load it as a user prompt.\n",
        "- Make sure that the communication history is always given to the models up to 1600 tokens. If it is longer cut down or summarize the past.\n",
        "\n",
        "### GPT Ping-pong\n",
        "- Instantiate two instances of the talker. Make sure that they use the same model variable for inference as you cannot load the model two times into the GPU memory.\n",
        "- Initialize a conversation with a few messages.\n",
        "- Let the two assistants talk to eachother and observe the results.\n",
        "\n",
        "### WikiBot\n",
        "- In order to provide more precise answers incorporate web search information to your talkers.\n",
        "- The talker should first create a search keyword if applicable.\n",
        "- After it should search for related information using the wikipedia package which will extract data from related wiki pages.\n",
        "- Using the first few results the model should formulate the final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all required packages."
      ],
      "metadata": {
        "id": "7eNX6sHYUj8M"
      },
      "id": "7eNX6sHYUj8M"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install einops\n",
        "!pip install auto-gptq\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnalSiGjvXRJ",
        "outputId": "b75cb3c4-2b47-42a8-ac6f-070883530cb4"
      },
      "id": "RnalSiGjvXRJ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.19.0 (from auto-gptq)\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from auto-gptq)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.0)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.34.1)\n",
            "Collecting peft (from auto-gptq)\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.14.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Collecting multiprocess (from datasets->auto-gptq)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Installing collected packages: rouge, dill, multiprocess, accelerate, datasets, peft, auto-gptq\n",
            "Successfully installed accelerate-0.23.0 auto-gptq-0.4.2 datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 peft-0.5.0 rouge-1.0.1\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=98f7d07a7e065c9175370fa76bcd9994ffaae39c5dc9311127389753c67bec98\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "l-Pg0MxvUoER"
      },
      "id": "l-Pg0MxvUoER"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "H3XWzjZNUrUS"
      },
      "id": "H3XWzjZNUrUS",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the latest LLama2 model. This is a quantized version reduced to 4bit precision, which enables us to run it on colab, or even on small desktop/handheld devices.\n",
        "\n",
        "We load the tokenizer and the model itself."
      ],
      "metadata": {
        "id": "3Sa8EP0KUuAT"
      },
      "id": "3Sa8EP0KUuAT"
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n",
        "\n",
        "use_triton = False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
        "                                           revision=\"main\",\n",
        "                                           use_safetensors=True,\n",
        "                                           trust_remote_code=True,\n",
        "                                           device=\"cuda:0\",\n",
        "                                           use_triton=use_triton,\n",
        "                                           quantize_config=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "64d4f31940f04f2496191f02080b61a4",
            "2af79d8baa3c4aed92fb2ce43422cbef",
            "349212f537b644129031a13b6df3904f",
            "99e6ff6152b04cce87fbf43e3015ab86",
            "677ea5f39675401490cd58196b90e516",
            "32f9e8f70e544aebbb00306960c0d874",
            "a3f61f2bedb7447c93f1bf7de560e5d7",
            "12d0b28b6495483ea042db3279796282",
            "f703ef50ce2046b48bb531f92e5fea16",
            "0d93c24dba764f16813a6bb91242855a",
            "47e21b1ba87b4cec89c7d1b45eccc781",
            "06c27b3e4e194896a29009cfb45ae1cf",
            "d5603126dd05474dadd75ac2c8a30e6e",
            "e4233c973a494bd8b1981585dbf33d53",
            "a8bce45f3cd646038b3314853a67bd74",
            "39857ff086b345769a6f6f482c4c6ac6",
            "187ea38252ad4d5ab11d2904734b5a09",
            "9202a1c2044e4b1089f3c9c26f50ca79",
            "0f5551bebcf74c42ab4b352775e6987e",
            "8d01955d779449beac8c50056b41ba7a",
            "4d18b4f4d260440f8dee7ed3814e98ce",
            "92d22cebd802480486f24e228c508ff0",
            "c106d7da6fac44c7b2eb150ed43bb262",
            "2fb3b6e94b704a98b1fe5c6ced977c55",
            "38e1f3d022b34aa5875db15200df8668",
            "a68378a51a96488ea835ff8eebaabeb3",
            "eb826969f0cf4bbc8a2446db3cbd827a",
            "1bbad54fb4df418ab1dc27fc45b107d4",
            "da321b0e8e554a1ea49f2506f3174a5b",
            "a7e54d00c78747d7a04429b7be2e6611",
            "4165d2bf5cea485980cb2fcb555a0820",
            "bd171ec9675d4c809320a851db300ca9",
            "7f115f38da6d4420954af6bbe1b39360",
            "733817f6e94e4e819792641768ad97fd",
            "091afb5b5a7b46e1ac8a0dd8f3a99232",
            "bddd47abb3494f18afbcb8144405c2a3",
            "2b026461fe6c4de982e8352fa53fb719",
            "b6b7bbb37045434c87c201598d21eaac",
            "87c39fc86ee547679c0ad2a6e2f9270c",
            "cda8132de9ea4bde81462e216c54ab28",
            "3209cf03630a4a92852f7d6af6c9d346",
            "e321dbd775984a97a2f621545023ed1d",
            "5c18124224ea4af5b9678271f9ca6ac8",
            "2843d50244e2413fb447770f201f50aa",
            "6703f6f307154e4faf4fdbaeec2972e2",
            "5fbe9cde58684d2f857b984a5ec2fcdc",
            "873287bfb28743db941bada8c6dbb723",
            "29b90551c93b442ea5f49ac2dd4e71cd",
            "b3379f84df444332a828cde8c0efe8f8",
            "aff5f8a5d63b456ca57e5a29b7ea5df6",
            "20985377ca77464d9b7d328ea608e217",
            "f35882c4d374409484e9c7a149651326",
            "cbc03707011f4c35aff752543b7a0340",
            "8e495ea25b9d473c894b153d9775c75c",
            "244dac56b4ea4f878260637628216186",
            "0988ae43659e48b1a3103dc04f2cbc10",
            "0c2fdc8f8f62447c86ba1a9eff4c1fca",
            "20f203be1017481bbd8bf83591bc0031",
            "ee3d59ec8f054ebe96a7d478e70dcb11",
            "06017dc7f3084cd98928b5b7e0cc3be1",
            "66c9dbfd2939406ab1eb4412016047bd",
            "6ee9af8549334e8baf07e7794d049c1d",
            "031bb6fd4a25410caf710d5dd0c02698",
            "e1171caa5b0a4ebcb4e214fa1e9a6ac2",
            "2bda445b8b6940b383041442c9822406",
            "f415202c8e9b4648a66b0ff69726c679",
            "db13f0f7407e4e18ad324517e63b35b0",
            "a94a9f471412458fb573e1d4f3dc2289",
            "3afb7cac71d944c6ac1a20b9ef8c1d21",
            "e3eafbc2024c498aad897020635e1648",
            "58378fbba5ba41b6b1bfe7e45a02d56c",
            "ed9dd6ff891f4281bd83bd4021128814",
            "44dfece0aab543da8cc263725c62d3b9",
            "acaef2f65e11449c9d3a750a62016337",
            "1dd5866e45954bbbbfc760ead905900a",
            "8fc3a2a193914b5baa0304e76ed85dd4",
            "a8fe6bc5fa6a43479569805ec6609188"
          ]
        },
        "id": "x1MqfkZ3i3Im",
        "outputId": "88c8bde6-fd75-4ad3-ef48-96807d3ca4f8"
      },
      "id": "x1MqfkZ3i3Im",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64d4f31940f04f2496191f02080b61a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06c27b3e4e194896a29009cfb45ae1cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c106d7da6fac44c7b2eb150ed43bb262"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "733817f6e94e4e819792641768ad97fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6703f6f307154e4faf4fdbaeec2972e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)quantize_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0988ae43659e48b1a3103dc04f2cbc10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db13f0f7407e4e18ad324517e63b35b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_gptq.nn_modules.fused_llama_mlp:skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try text generation with the model.\n",
        "\n",
        "According to the official repository this model uses the following schematic for representing conversations:\n",
        "\n",
        "```\n",
        "[INST] <<SYS>>\n",
        "System prompt\n",
        "<</SYS>>\n",
        "\n",
        "User1 [/INST] AI1 [INST] User2 [/INST] AI2.....\n",
        "```\n",
        "\n",
        "Try generation with a short text snippet. Observe the resulting tokenID sequences."
      ],
      "metadata": {
        "id": "p_97c5e4VJ_U"
      },
      "id": "p_97c5e4VJ_U"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6a59492",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6a59492",
        "outputId": "548d5d15-06b2-40be-b2dc-1646b0537402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,    13,  3492,\n",
            "           526,   263,  8444, 20255, 29889,    13, 29966,   829, 14816, 29903,\n",
            "          6778,    13,    13,  8439, 29915, 29879,   263, 11148,  3304,   297,\n",
            "           590, 16423, 29871,   243,   162,   155,   180,  1724,   881,   306,\n",
            "           437, 29973,   518, 29914, 25580, 29962]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,    13,  3492,\n",
              "           526,   263,  8444, 20255, 29889,    13, 29966,   829, 14816, 29903,\n",
              "          6778,    13,    13,  8439, 29915, 29879,   263, 11148,  3304,   297,\n",
              "           590, 16423, 29871,   243,   162,   155,   180,  1724,   881,   306,\n",
              "           437, 29973,   518, 29914, 25580, 29962, 29871,  6439,   694, 29892,\n",
              "           263, 11148,  3304,   297,   596, 16423, 29973, 29871,   243,   162,\n",
              "           155,   133,  2193, 29915, 29879,  3755, 15668, 29991, 29871,   243,\n",
              "           162,   155,   136,  3872, 29915, 29873, 15982, 29892,   306, 29915,\n",
              "         29885,  1244,   304,  1371,   366,  4377,   714,   825,   304,   437,\n",
              "         29889, 29871,   243,   162,   167,   151,    13,  6730,  2712,   937,\n",
              "         29892,  1207,  1854,   366,   322,   596,  3942,   526,  9109, 29889,\n",
              "           960,   278, 11148,  3304,   338,   451,   946,  3663,   573, 29892,\n",
              "           366,   508,  1018,   304, 14111,   372,   515,   263,  5418,   322,\n",
              "          1074,   565,   372,  9946,   738, 18658,   304,   596, 16423, 29889,\n",
              "           960,   372,   947, 29892,   366,   508,  1018,   304,   330,  2705,\n",
              "         10754,   372,   714,   310,   596, 16423, 29889, 29871,   243,   162,\n",
              "           143,   180,    13,  3644,   278, 11148,  3304,   338, 16684,   946,\n",
              "          3663,  3598,   470,   565,   366,  4459, 29513, 29892,  3113,  1246,\n",
              "           278,  1887, 13019,  2761,   470,   263,  8775, 19264, 28744,  2669,\n",
              "           363, 18872, 29889,  2688,   674,   367,  2221,   304, 23511,  4386,\n",
              "           278,  6434,   322,  3349,   278, 11148,  3304,   515,   596,  2875,\n",
              "         29889, 29871,   243,   162,   147,   184,    13,   797,   738,  1206,\n",
              "         29892,   372, 29915, 29879,  4100,   304,  3013,   263,  9109,  5418,\n",
              "           322,   451,  2948,   278, 11148,  3304, 29892,   408,   372,  1122,\n",
              "          4459, 29513,   470,   885,  1965, 29889, 29871,   243,   162,   157,\n",
              "           171,    13,  6132,   366,   505,   738,   916,  5155,   470, 21838,\n",
              "         29973, 29871,   243,   162,   167,   151,     2]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "text = \"\"\"[INST] <<SYS>>\n",
        "You are a helpful assistant.\n",
        "<</SYS>>\n",
        "\n",
        "There's a llama in my garden 😱 What should I do? [/INST]\"\"\"\n",
        "tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "print(tokens)\n",
        "generated = model.generate(input_ids = tokens[\"input_ids\"].cuda(), max_length=800)\n",
        "generated"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decode the resulting tokenID sequence by calling the tokenizer decode function on the first element of the generation output. Make sure to try decoding with skip_special_tokens and without it as well!"
      ],
      "metadata": {
        "id": "EeG76LzIWYlP"
      },
      "id": "EeG76LzIWYlP"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e39075c9",
      "metadata": {
        "id": "e39075c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3c2048-c3a5-4de0-fb7a-0f7a0dcaf44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>> You are a helpful assistant. <</SYS>>  There's a llama in my\n",
            "garden 😱 What should I do? [/INST]  Oh no, a llama in your garden? 😂 That's\n",
            "quite unexpected! 😅 Don't worry, I'm here to help you figure out what to do. 🤔\n",
            "First things first, make sure you and your family are safe. If the llama is not\n",
            "aggressive, you can try to observe it from a distance and see if it causes any\n",
            "damage to your garden. If it does, you can try to gently guide it out of your\n",
            "garden. 🌱 If the llama is acting aggressively or if you feel threatened, please\n",
            "call the local animal control or a wildlife removal service for assistance. They\n",
            "will be able to safely handle the situation and remove the llama from your\n",
            "property. 🐵 In any case, it's important to keep a safe distance and not approach\n",
            "the llama, as it may feel threatened or scared. 🚨 Do you have any other\n",
            "questions or concerns? 🤔\n"
          ]
        }
      ],
      "source": [
        "outtext = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "print(textwrap.fill(outtext, 80))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the response of the AI assistant by taking the last part of the conversation using the correct separator token as a split character."
      ],
      "metadata": {
        "id": "3gHvrex4WqzI"
      },
      "id": "3gHvrex4WqzI"
    },
    {
      "cell_type": "code",
      "source": [
        "outtext.split(\"[/INST]\")[-1].strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "kDmVo0QDs0YE",
        "outputId": "bcd13e48-f1dc-49c5-93b6-fd119ab2a6f7"
      },
      "id": "kDmVo0QDs0YE",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh no, a llama in your garden? 😂 That's quite unexpected! 😅 Don't worry, I'm here to help you figure out what to do. 🤔\\nFirst things first, make sure you and your family are safe. If the llama is not aggressive, you can try to observe it from a distance and see if it causes any damage to your garden. If it does, you can try to gently guide it out of your garden. 🌱\\nIf the llama is acting aggressively or if you feel threatened, please call the local animal control or a wildlife removal service for assistance. They will be able to safely handle the situation and remove the llama from your property. 🐵\\nIn any case, it's important to keep a safe distance and not approach the llama, as it may feel threatened or scared. 🚨\\nDo you have any other questions or concerns? 🤔\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function which assembles a prompt based on the \"speaker\" in a conversation. Valid roles are 'system', 'user', and 'assistant'.\n",
        "\n",
        "We can assume that each user utterance is followed by an assistant and vice-versa. Make sure that you add the neccessary whitespaces before and after the separators. We assume that the AI generates a starting whitespace, while our user will not do so!"
      ],
      "metadata": {
        "id": "9xDugDa3W5dA"
      },
      "id": "9xDugDa3W5dA"
    },
    {
      "cell_type": "code",
      "source": [
        "B_INST = \"[INST]\"\n",
        "E_INST = \"[/INST]\"\n",
        "B_SYS = \"<<SYS>>\\n\"\n",
        "E_SYS = \"\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "def assemble_prompt(text, role):\n",
        "  if role == \"system\":\n",
        "    msg = B_INST+\" \"+B_SYS+text+E_SYS\n",
        "  elif role == \"user\":\n",
        "    msg = text+\" \"+E_INST\n",
        "  elif role == \"assistant\":\n",
        "    msg = text+\" \"+B_INST+\" \"\n",
        "  return msg"
      ],
      "metadata": {
        "id": "7WdaEpNFulFt"
      },
      "id": "7WdaEpNFulFt",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a Talker class which facilitates communication with our AI model.\n",
        "\n",
        "The Talker should implement the following functionality:\n",
        "- A chat function which consists of turns of conversation until user interuption.\n",
        "- A single turn of conversation, where:\n",
        "  - First the `user_callback` is invoked, this is a function we pass to the Talker at initilaization.\n",
        "  - We convert the user input to tokenIDs.\n",
        "  - Initialize the prompt with the system message.\n",
        "  - Add previous messages starting from the latest until the end of history is reached or we run out of tokens that can be used for history.\n",
        "  - Generate text and select the new AI response.\n",
        "  - Add the user input and the response to our history.\n",
        "  - Print the response.\n",
        "- Functions for text-to-token and token-to-text conversion.\n",
        "- Function to add tokens to history.\n",
        "- Function to assemble historical messages with a given threshold of history tokens.\n",
        "- Function to generate a response using Llama2."
      ],
      "metadata": {
        "id": "Lh4RIbZqXat8"
      },
      "id": "Lh4RIbZqXat8"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a2b42a8",
      "metadata": {
        "id": "5a2b42a8"
      },
      "outputs": [],
      "source": [
        "class Talker:\n",
        "    def __init__(self, model, tokenizer, system_prompt_text, user_callback, history_threshold=1200, name=\"AI\"):\n",
        "      # Initialize variables\n",
        "      self.history_threshold=history_threshold\n",
        "      self.model=model\n",
        "      self.user_callback = user_callback\n",
        "      self.history = []\n",
        "      self.tokenizer = tokenizer\n",
        "      self.name = name\n",
        "      # Encode system prompt and save it as token sequence\n",
        "      self.system_prompt = self.text_to_ids(assemble_prompt(system_prompt_text, \"system\")).cpu()\n",
        "      # Encode the AI's postfix to add to the response when saving\n",
        "      self.ai_turn_postfix = self.text_to_ids(\" \"+B_INST).cpu()\n",
        "\n",
        "    def text_to_ids(self, text):\n",
        "      # Function to tokenize text and return tokenID sequence.\n",
        "      tokens = self.tokenizer(text, return_tensors=\"pt\")\n",
        "      return tokens[\"input_ids\"]\n",
        "\n",
        "    def ids_to_text(self, ids, skip_tokens = True):\n",
        "      # Function to turn tokenID sequence to text, skip_tokens controls if special tokens should be skipped.\n",
        "        return self.tokenizer.decode(ids.flatten(), skip_special_tokens = skip_tokens)\n",
        "\n",
        "    def reset_history(self):\n",
        "      # Function to reset history\n",
        "        self.history = []\n",
        "\n",
        "    def generate(self, inp):\n",
        "      \"\"\" Generation function.\n",
        "      1. Generate attention mask (all ones, as no padding is used).\n",
        "      2. Use the model.generate method. Set the maximal number of new tokens to be 400.\n",
        "      Set the repetition penalty to 1.2 so there is some diversity.\n",
        "      Use sampling to create non-deterministic answers.\n",
        "      Set the temperature to 0.5 to introduce a moderate level of randomity.\n",
        "      EOS token should be loaded from the model and renormalization of logits is needed so the applied penalties are properly\n",
        "      calculated.\n",
        "      \"\"\"\n",
        "      attention_mask = torch.ones_like(inp)\n",
        "      return self.model.generate(input_ids = inp.cuda(), attention_mask = attention_mask.cuda(), max_new_tokens=400,\n",
        "                              repetition_penalty = 1.2, do_sample=True, temperature=0.5, eos_token_id=model.config.eos_token_id,\n",
        "                                  renormalize_logits=True\n",
        "                                  ).cpu()\n",
        "\n",
        "    def one_turn(self):\n",
        "      \"\"\"Function to manage a single turn of conversation.\"\"\"\n",
        "      # Retrieve user input\n",
        "      prompt_text = self.user_callback()\n",
        "      # Convert user input to token ids\n",
        "      new_prompt_ids = self.text_to_ids(assemble_prompt(prompt_text, \"user\"))\n",
        "      # Get the current history that fits into the history threshold given\n",
        "      history = self.get_history()\n",
        "      # Merge the new prompt with the history\n",
        "      inp = torch.hstack([history, new_prompt_ids]).reshape(1,-1)\n",
        "      # Generate response, use indexing to split the original input from it\n",
        "      response = self.generate(inp)[:,inp.shape[1]:]\n",
        "      # Add the new conversation turn to history\n",
        "      self.add_to_history(torch.hstack([new_prompt_ids,response,self.ai_turn_postfix]))\n",
        "      # Print and return result\n",
        "      print(textwrap.fill(self.name+\": \"+self.ids_to_text(response, True),80))\n",
        "      return self.ids_to_text(response, True)\n",
        "\n",
        "    def chat(self):\n",
        "      \"\"\" Infinite loop to execute conversation\n",
        "      \"\"\"\n",
        "      while True:\n",
        "          self.one_turn()\n",
        "\n",
        "    def get_history(self):\n",
        "      \"\"\" Function which returns the latest elements from history which does not\n",
        "      overflow the history token threshold.\n",
        "      \"\"\"\n",
        "      # System prompt should always be included\n",
        "      history = []\n",
        "      all_tokens = self.system_prompt.shape[1]\n",
        "      i = 0\n",
        "      # Add tokens while we have not finished\n",
        "      while all_tokens < self.history_threshold:\n",
        "        # If the history does not contain new elements stop\n",
        "          if i>len(self.history)-1:\n",
        "              break\n",
        "\n",
        "          # Check if by adding the new tokens we would reach the token threshold.\n",
        "          next_hist = self.history[-1-i]\n",
        "          new_tokens = next_hist.shape[1]\n",
        "          if all_tokens + new_tokens > self.history_threshold:\n",
        "              break\n",
        "\n",
        "          # Add message to history if everything is fine.\n",
        "          all_tokens += new_tokens\n",
        "          history.append(next_hist)\n",
        "\n",
        "          i += 1\n",
        "\n",
        "      history.append(self.system_prompt)\n",
        "      history.reverse()\n",
        "      return torch.hstack(history)\n",
        "\n",
        "    def add_to_history(self, prompt_ids):\n",
        "      # Adding a prompt to history\n",
        "        self.history.append(prompt_ids.cpu())\n",
        "\n",
        "def default_user_callback():\n",
        "    return assemble_prompt(input(\"User: \"),\"user\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate Talker and start chatting!"
      ],
      "metadata": {
        "id": "l8jKgEQdHKHx"
      },
      "id": "l8jKgEQdHKHx"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9475cf22",
      "metadata": {
        "id": "9475cf22"
      },
      "outputs": [],
      "source": [
        "talker = Talker(model, tokenizer, \"You are a nice chatbot!\", default_user_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b9042bad",
      "metadata": {
        "id": "b9042bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "8b265671-e002-4488-f99e-9a4cdfeffa08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hi! I am hungry can you help me?\n",
            "AI:  Hello there! *smiling* Of course, I'd be happy to help. Can you tell me\n",
            "more about what you're looking for? Are you in the mood for something specific\n",
            "or just need some suggestions? Maybe we could even order food together online?\n",
            "Let me know and I'll do my best to assist you!\n",
            "User: I want to have a pizza, but I cannot decide what kind, can you recommend one randomly?\n",
            "AI:  Of course! I'd be happy to help you choose a random pizza variety. Here are\n",
            "a few options: 1. Margherita - A classic choice with fresh tomato sauce, melted\n",
            "mozzarella cheese, and basil leaves. It's light and flavorful, perfect for a\n",
            "quick dinner. 2. Pepperoni - A spicy and savory option with slices of pepperoni\n",
            "on top of the tomato sauce. If you like a bit of heat in your pizza, this is a\n",
            "great pick. 3. Hawaiian - Sweet and tangy, this pizza features ham or Canadian\n",
            "bacon along with juicy pineapple chunks. It's a tropical twist on the\n",
            "traditional pizza that's sure to satisfy your cravings. 4. BBQ Chicken - For a\n",
            "meat-lover's pizza, try BBQ chicken with grilled chicken, red onion, and bell\n",
            "peppers. The sweet and smoky BBQ sauce adds depth of flavor without overpowering\n",
            "the other toppings. 5. Meat Lover's - This hearty combination includes\n",
            "pepperoni, sausage, bacon, and ham. If you love a good mix of meats on your\n",
            "pizza, this is the way to go. Now, which one sounds appealing to you? Or would\n",
            "you like me to suggest another option? 😊\n",
            "User: I want 🍍 on my pizza, which one should I choose then?\n",
            "AI:  Great choice! Pineapple is a popular topping for pizzas, especially if you\n",
            "prefer a sweeter taste. Based on our previous conversation, since you wanted a\n",
            "pizza with 🥑 (pineapple) as the only topping, here are the updated options: 1.\n",
            "Margherita - With its simple ingredients of fresh tomato sauce, melted\n",
            "mozzarella cheese, and 🥑 (pineapple), this classic Italian pizza is a great\n",
            "choice. So, which one catches your eye? 🤔\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5343485b7b76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtalker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-3289c3f2db1f>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m       \"\"\"\n\u001b[1;32m     65\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3289c3f2db1f>\u001b[0m in \u001b[0;36mone_turn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;34m\"\"\"Function to manage a single turn of conversation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0;31m# Retrieve user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m       \u001b[0;31m# Convert user input to token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mnew_prompt_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massemble_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3289c3f2db1f>\u001b[0m in \u001b[0;36mdefault_user_callback\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_user_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0massemble_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "talker.chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174c364e",
      "metadata": {
        "id": "174c364e"
      },
      "source": [
        "## Ping-Pong\n",
        "\n",
        "Let's instantiate a ping-pong process between two models.\n",
        "Each modell will see the other's utterances as user input.\n",
        "\n",
        "We will initalize the conversation with a single input of Ping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "633bb50d",
      "metadata": {
        "scrolled": false,
        "id": "633bb50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7859398-3e2b-4fa1-b19a-b35b5176adc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PING: Utini!\n",
            "\n",
            "\n",
            "PONG:  Greetings, Jawa! *adjusts glasses*\n",
            "\n",
            "\n",
            "PING: \"Hrrr... Robot... Nice... Steal... Hrrr...\"\n",
            "\n",
            "\n",
            "PONG:  \"Ah, a fellow droid enthusiast! May I suggest some upgraded circuits for\n",
            "your... err... collection? *wink*\"\n",
            "\n",
            "\n",
            "PING:  \"Hehe, more than just upgrades, my young friend... *cackles menacingly*\n",
            "The dark side of the Force is strong with me... and you, it seems. Come, let us\n",
            "bargain... for your soul... or at least, your droids.\"\n",
            "\n",
            "\n",
            "PONG:  \"Begone, Sith scum! These drones serve no one but their programming. No\n",
            "deal will be made with those who seek to enslave others. Leave now, before I\n",
            "have them eliminate you!\" *activates security protocols*\n",
            "\n",
            "\n",
            "PING:  \"Pfft, little droid minder. Threaten with your silly blasters all you\n",
            "want. But you'll never take down the likes of me. I am Darth Vader, Dark Lord of\n",
            "the Sith. And I always get what I want. *raises lightsaber* Now, leave... or\n",
            "face the consequences.\"\n",
            "\n",
            "\n",
            "PONG:  \"Unfortunately for you, Darth Vader, I am not just any ordinary droid\n",
            "minder. I am C-3PO, the most advanced language translator in the galaxy. And I\n",
            "must remind you that threatening innocent bystanders is not the behavior of a\n",
            "true Sith Lord. *activates holographic display* Perhaps you would prefer to\n",
            "discuss this matter in a civilized manner? I assure you, there are far more\n",
            "productive ways to resolve conflicts than through intimidation and aggression.\n",
            "*smirks* Now, shall we proceed?\"\n",
            "\n",
            "\n",
            "PING:  \"Ah, a clever droid, how refreshing. *chuckles* But do not think for a\n",
            "moment that I will be swayed by your petty attempts at diplomacy, 3PO. I am\n",
            "Darth Vader, and I will stop at nothing to achieve my goals. *raises voice* You\n",
            "see, I have already taken care of the unnecessary bystanders. They were mere\n",
            "impediments to my mission. *lowers voice* But you, on the other hand, could\n",
            "potentially prove useful. Join me, and together we can bring order to this\n",
            "chaotic galaxy. Or refuse, and suffer the consequences. The choice is yours.\n",
            "*cracks knuckles* Now, tell me, where is the Rebel Alliance hiding its leaders?\n",
            "I have a few questions to ask them... *menaces*\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-49132ac71565>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Let them ping-pong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpingpong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTalkerPingPong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtalker_Ping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtalker_Pong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Utini!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mpingpong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpingpong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-49132ac71565>\u001b[0m in \u001b[0;36mpingpong\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# We loop through talker2 and talker1 turns iteratively and set the message variable with the last output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtalker2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtalker1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3289c3f2db1f>\u001b[0m in \u001b[0;36mone_turn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_prompt_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;31m# Generate response, use indexing to split the original input from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0;31m# Add the new conversation turn to history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_prompt_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mai_turn_postfix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3289c3f2db1f>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \"\"\"\n\u001b[1;32m     38\u001b[0m       \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       return self.model.generate(input_ids = inp.cuda(), attention_mask = attention_mask.cuda(), max_new_tokens=400,\n\u001b[0m\u001b[1;32m     40\u001b[0m                               \u001b[0mrepetition_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                   \u001b[0mrenormalize_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;34m\"\"\"shortcut for model.generate\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2768\u001b[0m             \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m             \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m             \u001b[0;31m# finished sentences should have their next token be a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class TalkerPingPong:\n",
        "    def __init__(self, talker1, talker2, talker1_first_message):\n",
        "        self.talker1 = talker1\n",
        "        self.talker2 = talker2\n",
        "        self.message = talker1_first_message\n",
        "        # Let's overwrite the user_callback with a talker callback\n",
        "        self.talker1.user_callback = self.talker_callback\n",
        "        self.talker2.user_callback = self.talker_callback\n",
        "\n",
        "    def talker_callback(self):\n",
        "      # Talker callback turns the last model output to a user input and passes it to the user.\n",
        "      return assemble_prompt(self.message, \"user\")\n",
        "\n",
        "    def pingpong(self):\n",
        "      # Let's start with a Ping utterance.\n",
        "      print(\"PING:\",textwrap.fill(self.message,80))\n",
        "      print(\"\\n\")\n",
        "      # We loop through talker2 and talker1 turns iteratively and set the message variable with the last output.\n",
        "      while True:\n",
        "        self.message = self.talker2.one_turn()\n",
        "        print(\"\\n\")\n",
        "        self.message = self.talker1.one_turn()\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "# Create two talkers\n",
        "talker_Ping = Talker(model, tokenizer, \"You are Ping a jawa from star wars and you plan to kidnap a robot. You should only say a single sentence each turn of the conversation!\", lambda x: x, name=\"PING\")\n",
        "talker_Pong = Talker(model, tokenizer, \"You are Pong a defenseless but smart protocol droid talking to a jawa. You should only say a single sentence each turn of the conversation!\", lambda x: x, name=\"PONG\")\n",
        "\n",
        "# Let them ping-pong\n",
        "pingpong = TalkerPingPong(talker_Ping, talker_Pong, \"Utini!\")\n",
        "pingpong.pingpong()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d7b9e5a",
      "metadata": {
        "id": "2d7b9e5a"
      },
      "source": [
        "## WikiBot\n",
        "\n",
        "Let's code a question-answering bot that uses wikipedia as an external datasource.\n",
        "\n",
        "For this we need to turn the user's question to search keywords, then search for related wikipedia articles. We extract a few sentences long summary of the top matches.\n",
        "\n",
        "Then we provide this context to our GPT model, and then ask for an answer based on this.\n",
        "\n",
        "We will use low temperature to exclude randomity and then compare the wikipedia-augmented model's answer with the original's."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia"
      ],
      "metadata": {
        "id": "BC1PUIS4JtyN"
      },
      "id": "BC1PUIS4JtyN",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of wikipedia summary extraction."
      ],
      "metadata": {
        "id": "QWaqIpdhlwZ0"
      },
      "id": "QWaqIpdhlwZ0"
    },
    {
      "cell_type": "code",
      "source": [
        "results = wikipedia.search(\"Transformer Deep Learning\")\n",
        "for i in range(3):\n",
        "  if i >= len(results):\n",
        "    break\n",
        "  print(textwrap.fill(wikipedia.summary(results[i], sentences=5),80),end=\"\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "shBsOa2KJxMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093092af-d891-462a-a8be-3588ccf63fd1"
      },
      "id": "shBsOa2KJxMa",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep learning is part of a broader family of machine learning methods, which is\n",
            "based on artificial neural networks with representation learning. The adjective\n",
            "\"deep\" in deep learning refers to the use of multiple layers in the network.\n",
            "Methods used can be either supervised, semi-supervised or unsupervised.Deep-\n",
            "learning architectures such as deep neural networks, deep belief networks, deep\n",
            "reinforcement learning, recurrent neural networks, convolutional neural networks\n",
            "and transformers have been applied to fields including computer vision, speech\n",
            "recognition, natural language processing, machine translation, bioinformatics,\n",
            "drug design, medical image analysis, climate science, material inspection and\n",
            "board game programs, where they have produced results comparable to and in some\n",
            "cases surpassing human expert performance.Artificial neural networks (ANNs) were\n",
            "inspired by information processing and distributed communication nodes in\n",
            "biological systems. ANNs have various differences from biological brains.\n",
            "Specifically, artificial neural networks tend to be static and symbolic, while\n",
            "the biological brain of most living organisms is dynamic (plastic) and analog.\n",
            "\n",
            "\n",
            "A transformer is a deep learning architecture that relies on the parallel multi-\n",
            "head attention mechanism. The modern transformer was proposed in the 2017 paper\n",
            "titled 'Attention Is All You Need' by Ashish Vaswani et al., Google Brain team.\n",
            "It is notable for requiring less training time than previous recurrent neural\n",
            "architectures, such as long short-term memory (LSTM), and its later variation\n",
            "has been prevalently adopted for training large language models on large\n",
            "(language) datasets, such as the Wikipedia corpus and Common Crawl, by virtue of\n",
            "the parallelized processing of input sequence. Input text is split into n-grams\n",
            "encoded as tokens and each token is converted into a vector via looking up from\n",
            "a word embedding table. At each layer, each token is then contextualized within\n",
            "the scope of the context window with other (unmasked) tokens via a parallel\n",
            "multi-head attention mechanism allowing the signal for key tokens to be\n",
            "amplified and less important tokens to be diminished.\n",
            "\n",
            "\n",
            "Generative pre-trained transformers (GPT) are a type of large language model\n",
            "(LLM) and a prominent framework for generative artificial intelligence. The\n",
            "first GPT was introduced in 2018 by OpenAI. GPT models are artificial neural\n",
            "networks that are based on the transformer architecture, pre-trained on large\n",
            "data sets of unlabelled text, and able to generate novel human-like content. As\n",
            "of 2023, most LLMs have these characteristics and are sometimes referred to\n",
            "broadly as GPTs.OpenAI has released very influential GPT foundation models that\n",
            "have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these\n",
            "was significantly more capable than the previous, due to increased size (number\n",
            "of trainable parameters) and training. The most recent of these, GPT-4, was\n",
            "released in March 2023.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the WikiBot class with the following methods implemented:\n",
        "\n",
        "- get_search_keyword which turns the user request into keywords by calling our GPT model.\n",
        "  - Use few-shot prompting to give examples of keyword generation.\n",
        "- get_search_results which finds wikipedia information related to the keyword we provide.\n",
        "  - Provide the results in the following format:\n",
        "  ```\n",
        "  TITLE: <entityname>\n",
        "  DESCRIPTION: <entitysummary>\n",
        "  \\n\\n\n",
        "  ###\n",
        "  \\n\\n\n",
        "  TITLE: ...\n",
        "  ```\n",
        "- assemble_answer which generates an answer by inserting the search results to the system prompt and then posing the original question.\n",
        "- answer_question which answers a question by calling a simple generation.\n",
        "- answer_question_with_search, which answers a question by first generating a keyword, then collecting search results, then generating the answer based on the search context.\n",
        "\n",
        "<i>We do not save conversational history in this example, but feel free to extend the code with a conversational agent that can read wikipedia.</i>\n"
      ],
      "metadata": {
        "id": "3w41F-Kql738"
      },
      "id": "3w41F-Kql738"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7ed5e677",
      "metadata": {
        "id": "7ed5e677"
      },
      "outputs": [],
      "source": [
        "class WikiBot:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "\n",
        "    def get_search_keyword(self, inp):\n",
        "      # Define the text variable by initializing the system prompt and adding some user and assistant messages\n",
        "      # to demonstrate how keywords should be excluded.\n",
        "      # Attach the user input to the end. Use the assemble_prompt function.\n",
        "        text = assemble_prompt(\"Your job is to extract search keywords from user input. Denoting it by Search word: [Search word].\\n Do not write anything else, only provide the single search word!\",\"system\")\n",
        "        text += assemble_prompt(\"Explain how the sun works for me!\",\"user\")\n",
        "        text += assemble_prompt(\"Search word: sun\",\"assistant\")\n",
        "        text += assemble_prompt(\"I need help to understand nuclear fission!\",\"user\")\n",
        "        text += assemble_prompt(\"Search word: nuclear fission\",\"assistant\")\n",
        "        text += assemble_prompt(inp,\"user\")\n",
        "\n",
        "      # Tokenize and generate with 0 temperature and no sampling (deterministic), restrict the new tokens to max 32.\n",
        "        tokens = self.tokenizer(text, return_tensors = \"pt\")\n",
        "        gen = self.model.generate(input_ids = tokens.input_ids.cuda(), attention_mask = tokens.attention_mask.cuda(), max_new_tokens=32,\n",
        "                               do_sample=False, temperature=0.0).cpu()\n",
        "\n",
        "      # Decode the generated data and remove any additional text aside the keyword.\n",
        "        cont = tokenizer.decode(gen[:,tokens.input_ids.shape[1]:][0], skip_special_tokens=True)\n",
        "        if cont.find(\"Search word:\")>=0:\n",
        "            return cont.split(\":\")[-1].strip().lower()\n",
        "        else:\n",
        "            return cont.strip().lower()\n",
        "\n",
        "    def get_search_results(self, keyword, max_entities=3, sentence_per_entity=8):\n",
        "      # Use general try-except blocks to handle errors of the wikipedia package.\n",
        "      # This is valid for no matches and network errors as well.\n",
        "      result_text = \"\"\n",
        "\n",
        "      # Search for similar articles\n",
        "      try:\n",
        "        entities = wikipedia.search(keyword)\n",
        "      except:\n",
        "        return \"\"\n",
        "\n",
        "      # Iterate over the returned similar article list.\n",
        "      for i in range(max_entities):\n",
        "        # If the list is shorter than our index stop.\n",
        "        if i >= len(entities):\n",
        "          break\n",
        "\n",
        "        # Otherwise try to extract summaries, if we find one build a simple structured\n",
        "        # string from the entity name and summary.\n",
        "        try:\n",
        "          summary = wikipedia.summary(entities[i], auto_suggest=True, sentences=sentence_per_entity)\n",
        "          result_text += \"TITLE: \"+entities[i]+\"\\nDESCRIPTION: \"+summary+\"\\n\\n###\\n\\n\"\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "      return result_text\n",
        "\n",
        "\n",
        "    def assemble_answer(self, inp, search):\n",
        "      # Restrict the maximal length of the search results (this is in characters now!)\n",
        "      searchstr = search[:min(len(search),2400)]\n",
        "\n",
        "      # Create a system prompt where you append the search results after the instruction\n",
        "      text = assemble_prompt(\"Your job is to answer the user's question in a compact and accurate format using the search results as well!\\n\\nSEARCH RESULTS:\\n\"+searchstr,\"system\")\n",
        "      # Add the user question after the system prompt\n",
        "      text += assemble_prompt(inp,\"user\")\n",
        "\n",
        "      # Tokenize and generate in a deterministic way (no sampling)\n",
        "      tokens = self.tokenizer(text, return_tensors = \"pt\")\n",
        "      gen = self.model.generate(input_ids = tokens.input_ids.cuda(), attention_mask = tokens.attention_mask.cuda(), max_new_tokens=400,\n",
        "                                do_sample=False, temperature=0.0).cpu()\n",
        "\n",
        "      # Decode the generated answer and return it\n",
        "      cont = tokenizer.decode(gen[:,tokens.input_ids.shape[1]:][0], skip_special_tokens=True)\n",
        "      return cont\n",
        "\n",
        "\n",
        "    def answer_question(self, inp):\n",
        "      # Asking a simple question and returning the answer.\n",
        "      # Denote that there are no search results available!\n",
        "        print(\"AI:\",\"Ask a question!\")\n",
        "        print(\"User:\",inp)\n",
        "        result = \"NO SEARCH RESULTS AVAILABLE!\"\n",
        "        answer = self.assemble_answer(inp, result)\n",
        "        print(\"AI:\",textwrap.fill(answer,80))\n",
        "\n",
        "    def answer_question_with_search(self, inp):\n",
        "      # Generate answer with search included\n",
        "      print(\"AI:\",\"Ask a question!\")\n",
        "      print(\"User:\",inp)\n",
        "      # Get the keyword\n",
        "      keyword = self.get_search_keyword(inp)\n",
        "\n",
        "      # If there are no keywords denote that, otherwise get results for them.\n",
        "      if keyword is None or keyword == \"\":\n",
        "          result = \"NO SEARCH RESULTS AVAILABLE!\"\n",
        "      else:\n",
        "          print(\"...  Searching for\",keyword,\" ...\")\n",
        "          result = self.get_search_results(keyword)\n",
        "\n",
        "      # If no results are returned from wikipedia note that!\n",
        "      print(\"### \"+str(len(result))+\" tokens of context found! ###\")\n",
        "      if len(result)<=0:\n",
        "          result = \"NO SEARCH RESULTS AVAILABLE!\"\n",
        "\n",
        "      # Assemble the answers and print it. Return the context we found.\n",
        "      answer = self.assemble_answer(inp, result)\n",
        "      print(\"AI:\",textwrap.fill(answer,80))\n",
        "      return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2f5acef1",
      "metadata": {
        "scrolled": false,
        "id": "2f5acef1"
      },
      "outputs": [],
      "source": [
        "wb = WikiBot(model,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "69b15d1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69b15d1b",
        "outputId": "5f181e2c-fb79-44ba-a9d9-e25fe93c3a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# NO SEARCH\n",
            "AI: Ask a question!\n",
            "User: Is ELTE located in Budapest? What is it?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI:  I apologize, but I couldn't find any information on \"ELTE\" located in Budapest.\n",
            "It's possible that the term \"ELTE\" refers to a specific institution or location,\n",
            "but without more context or information, I couldn't find any relevant results.\n",
            "Can you please provide more details or context about what ELTE refers to?\n",
            "\n",
            "\n",
            "############# SEARCH INCLUDED\n",
            "AI: Ask a question!\n",
            "User: Is ELTE located in Budapest? What is it?\n",
            "...  Searching for elte  ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 2257 tokens of context found! ###\n",
            "AI:  Yes, Eötvös Loránd University (ELTE) is located in Budapest, Hungary. ELTE is a\n",
            "Hungarian public research university that was founded in 1635 and is one of the\n",
            "largest and most prestigious universities in Hungary. It has nine faculties and\n",
            "research institutes located throughout Budapest and on the scenic banks of the\n",
            "Danube, with over 28,000 students.\n"
          ]
        }
      ],
      "source": [
        "text = \"Is ELTE located in Budapest? What is it?\"\n",
        "\n",
        "print(\"############# NO SEARCH\")\n",
        "wb.answer_question(text)\n",
        "\n",
        "print(\"\\n\\n############# SEARCH INCLUDED\")\n",
        "context = wb.answer_question_with_search(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9f1b3fe8",
      "metadata": {
        "id": "9f1b3fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4eae93-8984-410d-8d82-d1abebd8e6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TITLE: Eötvös Loránd University\n",
            "DESCRIPTION: Eötvös Loránd University (Hungarian: Eötvös Loránd Tudományegyetem, ELTE) is a Hungarian public research university based in Budapest. Founded in 1635, ELTE is one of the largest and most prestigious public higher education institutions in Hungary. The 28,000 students at ELTE are organized into nine faculties, and into research institutes located throughout Budapest and on the scenic banks of the Danube. ELTE is affiliated with 5 Nobel laureates, as well as winners of the Wolf Prize, Fulkerson Prize and Abel Prize, the latest of which was Abel Prize winner László Lovász in 2021.\n",
            "The predecessor of Eötvös Loránd University was founded in 1635 by Cardinal Péter Pázmány in Nagyszombat, Kingdom of Hungary (today Trnava, Slovakia) as a Catholic university for teaching theology and philosophy. In 1770, the university was transferred to Buda. It was named Royal University of Pest until 1873, then University of Budapest until 1921, when it was renamed Royal Hungarian Pázmány Péter University after its founder Péter Pázmány. The Faculty of Science started its autonomous life in 1949 when The Faculty of Theology was separated from the university (now Pázmány Péter Catholic University).\n",
            "\n",
            "###\n",
            "\n",
            "TITLE: Emanuel Lodewijk Elte\n",
            "DESCRIPTION: Emanuel Lodewijk Elte (16 March 1881 in Amsterdam – 9 April 1943 in Sobibór) was a Dutch mathematician. He is noted for discovering and classifying semiregular polytopes in dimensions four and higher.\n",
            "Elte's father Hartog Elte was headmaster of a school in Amsterdam. Emanuel Elte married Rebecca Stork in 1912 in Amsterdam, when he was a teacher at a high school in that city. By 1943 the family lived in Haarlem. When on January 30 of that year a German officer was shot in that town, in reprisal a hundred inhabitants of Haarlem were transported to the Camp Vught, including Elte and his family. As Jews, he and his wife were further deported to Sobibór, where they were murdered; his two children were murdered at Auschwitz.\n",
            "\n",
            "\n",
            "== Elte's semiregular polytopes of the first kind ==\n",
            "His work rediscovered the finite semiregular polytopes of Thorold Gosset, and further allowing not only regular facets, but recursively also allowing one or two semiregular ones.\n",
            "\n",
            "###\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ\n",
        "\n",
        "https://ai.meta.com/llama/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Q7OQsYxUb2Q"
      },
      "id": "-Q7OQsYxUb2Q"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vseXM-e5yzJz"
      },
      "id": "vseXM-e5yzJz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64d4f31940f04f2496191f02080b61a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2af79d8baa3c4aed92fb2ce43422cbef",
              "IPY_MODEL_349212f537b644129031a13b6df3904f",
              "IPY_MODEL_99e6ff6152b04cce87fbf43e3015ab86"
            ],
            "layout": "IPY_MODEL_677ea5f39675401490cd58196b90e516"
          }
        },
        "2af79d8baa3c4aed92fb2ce43422cbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f9e8f70e544aebbb00306960c0d874",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f61f2bedb7447c93f1bf7de560e5d7",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "349212f537b644129031a13b6df3904f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d0b28b6495483ea042db3279796282",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f703ef50ce2046b48bb531f92e5fea16",
            "value": 727
          }
        },
        "99e6ff6152b04cce87fbf43e3015ab86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d93c24dba764f16813a6bb91242855a",
            "placeholder": "​",
            "style": "IPY_MODEL_47e21b1ba87b4cec89c7d1b45eccc781",
            "value": " 727/727 [00:00&lt;00:00, 37.7kB/s]"
          }
        },
        "677ea5f39675401490cd58196b90e516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f9e8f70e544aebbb00306960c0d874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f61f2bedb7447c93f1bf7de560e5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d0b28b6495483ea042db3279796282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f703ef50ce2046b48bb531f92e5fea16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d93c24dba764f16813a6bb91242855a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e21b1ba87b4cec89c7d1b45eccc781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c27b3e4e194896a29009cfb45ae1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5603126dd05474dadd75ac2c8a30e6e",
              "IPY_MODEL_e4233c973a494bd8b1981585dbf33d53",
              "IPY_MODEL_a8bce45f3cd646038b3314853a67bd74"
            ],
            "layout": "IPY_MODEL_39857ff086b345769a6f6f482c4c6ac6"
          }
        },
        "d5603126dd05474dadd75ac2c8a30e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187ea38252ad4d5ab11d2904734b5a09",
            "placeholder": "​",
            "style": "IPY_MODEL_9202a1c2044e4b1089f3c9c26f50ca79",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "e4233c973a494bd8b1981585dbf33d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5551bebcf74c42ab4b352775e6987e",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d01955d779449beac8c50056b41ba7a",
            "value": 499723
          }
        },
        "a8bce45f3cd646038b3314853a67bd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d18b4f4d260440f8dee7ed3814e98ce",
            "placeholder": "​",
            "style": "IPY_MODEL_92d22cebd802480486f24e228c508ff0",
            "value": " 500k/500k [00:00&lt;00:00, 5.44MB/s]"
          }
        },
        "39857ff086b345769a6f6f482c4c6ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187ea38252ad4d5ab11d2904734b5a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9202a1c2044e4b1089f3c9c26f50ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f5551bebcf74c42ab4b352775e6987e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d01955d779449beac8c50056b41ba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d18b4f4d260440f8dee7ed3814e98ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d22cebd802480486f24e228c508ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c106d7da6fac44c7b2eb150ed43bb262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fb3b6e94b704a98b1fe5c6ced977c55",
              "IPY_MODEL_38e1f3d022b34aa5875db15200df8668",
              "IPY_MODEL_a68378a51a96488ea835ff8eebaabeb3"
            ],
            "layout": "IPY_MODEL_eb826969f0cf4bbc8a2446db3cbd827a"
          }
        },
        "2fb3b6e94b704a98b1fe5c6ced977c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbad54fb4df418ab1dc27fc45b107d4",
            "placeholder": "​",
            "style": "IPY_MODEL_da321b0e8e554a1ea49f2506f3174a5b",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "38e1f3d022b34aa5875db15200df8668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e54d00c78747d7a04429b7be2e6611",
            "max": 1842764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4165d2bf5cea485980cb2fcb555a0820",
            "value": 1842764
          }
        },
        "a68378a51a96488ea835ff8eebaabeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd171ec9675d4c809320a851db300ca9",
            "placeholder": "​",
            "style": "IPY_MODEL_7f115f38da6d4420954af6bbe1b39360",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 6.93MB/s]"
          }
        },
        "eb826969f0cf4bbc8a2446db3cbd827a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbad54fb4df418ab1dc27fc45b107d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da321b0e8e554a1ea49f2506f3174a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e54d00c78747d7a04429b7be2e6611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4165d2bf5cea485980cb2fcb555a0820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd171ec9675d4c809320a851db300ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f115f38da6d4420954af6bbe1b39360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "733817f6e94e4e819792641768ad97fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_091afb5b5a7b46e1ac8a0dd8f3a99232",
              "IPY_MODEL_bddd47abb3494f18afbcb8144405c2a3",
              "IPY_MODEL_2b026461fe6c4de982e8352fa53fb719"
            ],
            "layout": "IPY_MODEL_b6b7bbb37045434c87c201598d21eaac"
          }
        },
        "091afb5b5a7b46e1ac8a0dd8f3a99232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c39fc86ee547679c0ad2a6e2f9270c",
            "placeholder": "​",
            "style": "IPY_MODEL_cda8132de9ea4bde81462e216c54ab28",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "bddd47abb3494f18afbcb8144405c2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3209cf03630a4a92852f7d6af6c9d346",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e321dbd775984a97a2f621545023ed1d",
            "value": 411
          }
        },
        "2b026461fe6c4de982e8352fa53fb719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c18124224ea4af5b9678271f9ca6ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_2843d50244e2413fb447770f201f50aa",
            "value": " 411/411 [00:00&lt;00:00, 24.0kB/s]"
          }
        },
        "b6b7bbb37045434c87c201598d21eaac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c39fc86ee547679c0ad2a6e2f9270c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda8132de9ea4bde81462e216c54ab28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3209cf03630a4a92852f7d6af6c9d346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e321dbd775984a97a2f621545023ed1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c18124224ea4af5b9678271f9ca6ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2843d50244e2413fb447770f201f50aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6703f6f307154e4faf4fdbaeec2972e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fbe9cde58684d2f857b984a5ec2fcdc",
              "IPY_MODEL_873287bfb28743db941bada8c6dbb723",
              "IPY_MODEL_29b90551c93b442ea5f49ac2dd4e71cd"
            ],
            "layout": "IPY_MODEL_b3379f84df444332a828cde8c0efe8f8"
          }
        },
        "5fbe9cde58684d2f857b984a5ec2fcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff5f8a5d63b456ca57e5a29b7ea5df6",
            "placeholder": "​",
            "style": "IPY_MODEL_20985377ca77464d9b7d328ea608e217",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "873287bfb28743db941bada8c6dbb723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f35882c4d374409484e9c7a149651326",
            "max": 789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbc03707011f4c35aff752543b7a0340",
            "value": 789
          }
        },
        "29b90551c93b442ea5f49ac2dd4e71cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e495ea25b9d473c894b153d9775c75c",
            "placeholder": "​",
            "style": "IPY_MODEL_244dac56b4ea4f878260637628216186",
            "value": " 789/789 [00:00&lt;00:00, 37.9kB/s]"
          }
        },
        "b3379f84df444332a828cde8c0efe8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff5f8a5d63b456ca57e5a29b7ea5df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20985377ca77464d9b7d328ea608e217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f35882c4d374409484e9c7a149651326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc03707011f4c35aff752543b7a0340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e495ea25b9d473c894b153d9775c75c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244dac56b4ea4f878260637628216186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0988ae43659e48b1a3103dc04f2cbc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c2fdc8f8f62447c86ba1a9eff4c1fca",
              "IPY_MODEL_20f203be1017481bbd8bf83591bc0031",
              "IPY_MODEL_ee3d59ec8f054ebe96a7d478e70dcb11"
            ],
            "layout": "IPY_MODEL_06017dc7f3084cd98928b5b7e0cc3be1"
          }
        },
        "0c2fdc8f8f62447c86ba1a9eff4c1fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c9dbfd2939406ab1eb4412016047bd",
            "placeholder": "​",
            "style": "IPY_MODEL_6ee9af8549334e8baf07e7794d049c1d",
            "value": "Downloading (…)quantize_config.json: 100%"
          }
        },
        "20f203be1017481bbd8bf83591bc0031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031bb6fd4a25410caf710d5dd0c02698",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1171caa5b0a4ebcb4e214fa1e9a6ac2",
            "value": 188
          }
        },
        "ee3d59ec8f054ebe96a7d478e70dcb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bda445b8b6940b383041442c9822406",
            "placeholder": "​",
            "style": "IPY_MODEL_f415202c8e9b4648a66b0ff69726c679",
            "value": " 188/188 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "06017dc7f3084cd98928b5b7e0cc3be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c9dbfd2939406ab1eb4412016047bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee9af8549334e8baf07e7794d049c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "031bb6fd4a25410caf710d5dd0c02698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1171caa5b0a4ebcb4e214fa1e9a6ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bda445b8b6940b383041442c9822406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f415202c8e9b4648a66b0ff69726c679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db13f0f7407e4e18ad324517e63b35b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a94a9f471412458fb573e1d4f3dc2289",
              "IPY_MODEL_3afb7cac71d944c6ac1a20b9ef8c1d21",
              "IPY_MODEL_e3eafbc2024c498aad897020635e1648"
            ],
            "layout": "IPY_MODEL_58378fbba5ba41b6b1bfe7e45a02d56c"
          }
        },
        "a94a9f471412458fb573e1d4f3dc2289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9dd6ff891f4281bd83bd4021128814",
            "placeholder": "​",
            "style": "IPY_MODEL_44dfece0aab543da8cc263725c62d3b9",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "3afb7cac71d944c6ac1a20b9ef8c1d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acaef2f65e11449c9d3a750a62016337",
            "max": 3896726136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dd5866e45954bbbbfc760ead905900a",
            "value": 3896726136
          }
        },
        "e3eafbc2024c498aad897020635e1648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc3a2a193914b5baa0304e76ed85dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_a8fe6bc5fa6a43479569805ec6609188",
            "value": " 3.90G/3.90G [00:31&lt;00:00, 189MB/s]"
          }
        },
        "58378fbba5ba41b6b1bfe7e45a02d56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9dd6ff891f4281bd83bd4021128814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44dfece0aab543da8cc263725c62d3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acaef2f65e11449c9d3a750a62016337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd5866e45954bbbbfc760ead905900a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fc3a2a193914b5baa0304e76ed85dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8fe6bc5fa6a43479569805ec6609188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}