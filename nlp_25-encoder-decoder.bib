@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume=3,
  pages={1137--1155},
  year=2003,
  url={https://bit.ly/3rkKa4M}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@article{levy2014neural,
  title={Neural word embedding as implicit matrix factorization},
  author={Levy, Omer and Goldberg, Yoav},
  journal={Advances in neural information processing systems},
  volume=27,
  pages={2177--2185},
  year=2014,
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013},
  url={https://arxiv.org/pdf/1301.3781.pdf}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume=26,
  pages={3111--3119},
  year=2013,
  url={https://bit.ly/2WxL8MT}}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014},
  url={https://nlp.stanford.edu/pubs/glove.pdf}
}

@unpublished{jurafsky2019speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2019},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{levy2015improving,
  title={Improving distributional similarity with lessons learned from word embeddings},
  author={Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  journal={Transactions of the Association for Computational Linguistics},
  volume=3,
  pages={211--225},
  year=2015,
  publisher={MIT Press},
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{heinzerling2017bpemb,
  title={BPEmb: Tokenization-free pre-trained subword embeddings in 275 languages},
  author={Heinzerling, Benjamin and Strube, Michael},
  journal={arXiv preprint arXiv:1710.02187},
  year={2017},
  url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  url={https://bit.ly/3hoXoJx}
}

@unpublished{olah2015understanding,
  title={Understanding {LSTM} networks},
  author={Olah, Christopher},
  year={2015},
  url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library},
  url={https://crl.ucsd.edu/~elman/Papers/fsit.pdf}
}


@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={1171--1179},
  year={2015},
  url={https://bit.ly/3rHrYCO}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{chorowski2015attention,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{karpathy2015unreasonable,
  title={The unreasonable effectiveness of recurrent neural networks. {B}log post},
  author={Karpathy, Andrej},
  url={http://karpathy.github.io/2015/05/21/rnn-effectiveness},
  year={2015}
  }

@article{falcon2018taming,
  title={Taming {LSTM}s. {B}log post},
  author={Falcon, William},
  url={https://bit.ly/38PFJ9T},
  year={2018}
  }

@article{minaee2019deep,
  title={Deep-sentiment: Sentiment analysis using ensemble of {CNN} and bi-{LSTM} models},
  author={Minaee, Shervin and Azimi, Elham and Abdolrashidi, AmirAli},
  journal={arXiv preprint arXiv:1904.04206},
  year={2019},
  url={https://arxiv.org/pdf/1904.04206.pdf}
}

@article{faust2018automated,
  title={Automated detection of atrial fibrillation using long short-term memory network with RR interval signals},
  author={Faust, Oliver and Shenfield, Alex and Kareem, Murtadha and San, Tan Ru and Fujita, Hamido and Acharya, U Rajendra},
  journal={Computers in biology and medicine},
  volume={102},
  pages={327--335},
  year={2018},
  publisher={Elsevier},
  url={https://bit.ly/2LdAEA0}
}

 @book{murphy2021pml,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2021,
 url = "http://mlbayes.ai"
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{choromanski2022rethinking,
      title={Rethinking Attention with Performers}, 
      author={Krzysztof Choromanski and Valerii Likhosherstov and David Dohan and Xingyou Song and Andreea Gane and Tamas Sarlos and Peter Hawkins and Jared Davis and Afroz Mohiuddin and Lukasz Kaiser and David Belanger and Lucy Colwell and Adrian Weller},
      year={2022},
      eprint={2009.14794},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{grigsby2023longrange,
      title={Long-Range Transformers for Dynamic Spatiotemporal Forecasting}, 
      author={Jake Grigsby and Zhe Wang and Nam Nguyen and Yanjun Qi},
      year={2023},
      eprint={2109.12218},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{wang2020position,
  title={What do position embeddings learn? an empirical study of pre-trained language model positional encoding},
  author={Wang, Yu-An and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2010.04903},
  year={2020}
}

@phdthesis{elbayad2020rethinking,
  title={Rethinking the Design of Sequence-to-Sequence Models for Efficient Machine Translation},
  author={Elbayad, Maha},
  year={2020},
  school={Universit{\'e} Grenoble Alpes [2020-....]}
}

@misc{sun2023retentive,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@phdthesis{luong2016neural,
  title={Neural machine translation},
  author={Luong, Minh-Thang},
  year={2016},
  school={Stanford University},
  url={https://bit.ly/3hJ1wEo}
}

@book{koopman2013introduction,
  title={An introduction to syntactic analysis and theory},
  author={Koopman, Hilda and Sportiche, Dominique and Stabler, Edward},
  year={2013},
  publisher={John Wiley \& Sons},
  url = {https://linguistics.ucla.edu/people/stabler/isat.pdf}
}

@article{nivre2013beyond,
  title = {Beyond {MaltParser}. {P}resentation},
  author = {Nivre, Joakim},
  year = {2013},
  url = {https://bit.ly/3q2jm86}
}

@inproceedings{nivre-nilsson-2005-pseudo,
    title = "Pseudo-Projective Dependency Parsing",
    author = "Nivre, Joakim  and
      Nilsson, Jens",
    booktitle = "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05)",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P05-1013",
    doi = "10.3115/1219840.1219853",
    pages = "99--106",
}

@inproceedings{huang2009bilingually,
  title={Bilingually-constrained (monolingual) shift-reduce parsing},
  author={Huang, Liang and Jiang, Wenbin and Liu, Qun},
  booktitle={Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  pages={1222--1231},
  year=2009,
  url={https://dl.acm.org/doi/10.5555/1699648.1699668}
}

@inproceedings{chen2014fast,
  title={A fast and accurate dependency parser using neural networks},
  author={Chen, Danqi and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={740--750},
  year={2014},
  url={https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf}
}

@article{dozat2016deep,
  title={Deep biaffine attention for neural dependency parsing},
  author={Dozat, Timothy and Manning, Christopher D},
  journal={arXiv preprint arXiv:1611.01734},
  year={2016},
  url={https://arxiv.org/pdf/1611.01734.pdf}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018},
  url={https://arxiv.org/pdf/1802.05365.pdf}
}

@inproceedings{akbik2018contextual,
  title={Contextual string embeddings for sequence labeling},
  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={1638--1649},
  year={2018},
  url={http://alanakbik.github.io/papers/coling2018.pdf}
}

@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}

@misc{carion2020endtoend,
      title={End-to-End Object Detection with Transformers}, 
      author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
      year={2020},
      eprint={2005.12872},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lin2021endtoend,
      title={End-to-End Human Pose and Mesh Reconstruction with Transformers}, 
      author={Kevin Lin and Lijuan Wang and Zicheng Liu},
      year={2021},
      eprint={2012.09760},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zheng2021rethinking,
      title={Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers}, 
      author={Sixiao Zheng and Jiachen Lu and Hengshuang Zhao and Xiatian Zhu and Zekun Luo and Yabiao Wang and Yanwei Fu and Jianfeng Feng and Tao Xiang and Philip H. S. Torr and Li Zhang},
      year={2021},
      eprint={2012.15840},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yu2022coca,
      title={CoCa: Contrastive Captioners are Image-Text Foundation Models}, 
      author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
      year={2022},
      eprint={2205.01917},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{oquab2023dinov2,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2023},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{caron2021emerging,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu2022swin,
      title={Swin Transformer V2: Scaling Up Capacity and Resolution}, 
      author={Ze Liu and Han Hu and Yutong Lin and Zhuliang Yao and Zhenda Xie and Yixuan Wei and Jia Ning and Yue Cao and Zheng Zhang and Li Dong and Furu Wei and Baining Guo},
      year={2022},
      eprint={2111.09883},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Touvron2022DeiTIR,
  title={DeiT III: Revenge of the ViT},
  author={Hugo Touvron and Matthieu Cord and Herve Jegou},
  journal={arXiv preprint arXiv:2204.07118},
  year={2022},
}

@InProceedings{pmlr-v139-touvron21a,
  title =     {Training data-efficient image transformers &amp; distillation through attention},
  author =    {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
  booktitle = {International Conference on Machine Learning},
  pages =     {10347--10357},
  year =      {2021},
  volume =    {139},
  month =     {July}
}

@misc{yuan2021tokenstotoken,
      title={Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet}, 
      author={Li Yuan and Yunpeng Chen and Tao Wang and Weihao Yu and Yujun Shi and Zihang Jiang and Francis EH Tay and Jiashi Feng and Shuicheng Yan},
      year={2021},
      eprint={2101.11986},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017},
  url={https://arxiv.org/pdf/1706.03762.pdf}
}

@article{alammar2018illustrated,
  title={The illustrated transformer. {B}log post},
  author={Alammar, Jay},
  year={2018},
  url={http://jalammar.github.io/illustrated-transformer/}
  }

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://bit.ly/3qtMGop}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018},
  url={https://arxiv.org/abs/1810.04805}
}

@article{horev2018bert,
  title={{BERT} -- State of the Art Language Model. {B}log post},
  author={Horev, Rani},
  url={https://bit.ly/3bC6xNU},
  year={2018}
  }

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019},
  url={https://arxiv.org/pdf/1910.01108.pdf}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={arXiv preprint arXiv:2007.14062},
  year={2020},
  url={https://arxiv.org/pdf/2007.14062.pdf}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020},
  url={https://arxiv.org/pdf/2005.14165.pdf}
}

@InCollection{sep-compositionality,
	author       =	{Szab\'o, Zolt\'an Gendler},
	title        =	{{Compositionality}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	year         =	{2020},
	edition      =	{Fall 2020},
	publisher    =	{Metaphysics Research Lab, Stanford},
	url ={https://stanford.io/3nLH0UJ}
}

@article{navigli2009word,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM computing surveys (CSUR)},
  volume={41},
  number={2},
  pages={1--69},
  year={2009},
  publisher={ACM New York, NY, USA},
  url={https://bit.ly/2LwiQAP}
}

@misc{buutbogel2009fsmorph,
  title={Finite State Morphology Tutorial},
  author={Butt, Miriam and B\"ogel, Tina},
  year={2009},
  url={https://bit.ly/3sm44fx}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020},
  url={https://arxiv.org/abs/2005.00796}
}

@misc{hafner2018tfdistvae,
  author = {Hafner, Danijar},
  title = {Building Variational Auto-Encoders in TensorFlow},
  year = {2018},
  howpublished = {Blog post},
  url = {https://danijar.com/building-variational-auto-encoders-in-tensorflow/}
}


@misc{aqueel2023vae,
  author = {Anwar, Aqeel},
  title = {Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE)},
  year = {2021},
  howpublished = {Blog post},
  url = {https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2}
}

@article{doersch2016tutorial,
  title={Tutorial on variational autoencoders},
  author={Doersch, Carl},
  journal={arXiv preprint arXiv:1606.05908},
  year={2016},
  url={https://arxiv.org/pdf/1606.05908.pdf}
}

 @book{pml2Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: Advanced Topics",
 publisher = "MIT Press",
 year = 2023,
 url = "http://probml.github.io/book2"
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017},
  url={https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf}
}

@misc{askary2020intuitive,
  title={Intuitive Explanation of Straight-Through Estimators with PyTorch Implementation},
  author={Askary, Hassan},
  year={2020},
  publisher={Blog post},
  url={https://hassanaskary.medium.com/intuitive-explanation-of-straight-through-estimators-with-pytorch-implementation-71d99d25d9d0}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR},
  url={https://arxiv.org/abs/2102.12092}
}

@inproceedings{li2023trocr,
  title={Trocr: Transformer-based optical character recognition with pre-trained models},
  author={Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={11},
  pages={13094--13102},
  year={2023}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023},
  url={https://arxiv.org/pdf/2304.08485.pdf}
}

@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023},
  url={https://arxiv.org/pdf/2310.03744.pdf}
}
