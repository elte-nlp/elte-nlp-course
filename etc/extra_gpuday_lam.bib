@book{deacon1997symbolic,
  title={The symbolic species: The co-evolution of language and the brain},
  author={Deacon, Terrence William},
  number={202},
  year={1997},
  publisher={WW Norton \& Company}
}

@book{skinner1957verbal,
  title={Verbal behavior},
  author={Skinner, Burrhus Frederic},
  year={1957},
  publisher={New York: Appleton-Century-Crofts}
}

@book{cook2014chomsky,
  title={Chomsky's universal grammar: An introduction},
  author={Cook, Vivian and Newson, Mark},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{pinker2003language,
  title={The language instinct: How the mind creates language},
  author={Pinker, Steven},
  year={2003},
  publisher={Penguin uK}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017},
  url={https://arxiv.org/pdf/1706.03762.pdf}
}

@book{lenci2023distributional,
  title={Distributional semantics},
  author={Lenci, Alessandro and Sahlgren, Magnus},
  year={2023},
  publisher={Cambridge University Press}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  year={2019},
}

@misc{sun2023retentive,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{hu2022lora,
  title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@online{Llamacpp,
  author = {Georgi Gerganov},
  title = {llama.cpp - Inference of Meta's LLaMA model (and others) in pure C/C++},
  year = 2023,
  url = {https://github.com/ggerganov/llama.cpp},
  urldate = {2024-03-01}
}

@misc{agrawal2023sarathi,
      title={SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills}, 
      author={Amey Agrawal and Ashish Panwar and Jayashree Mohan and Nipun Kwatra and Bhargav S. Gulavani and Ramachandran Ramjee},
      year={2023},
      eprint={2308.16369},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{willard2023efficient,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sitdikov2022classifiers,
      title={Classifiers are Better Experts for Controllable Text Generation}, 
      author={Askhat Sitdikov and Nikita Balagansky and Daniil Gavrilov and Alexander Markov},
      year={2022},
      eprint={2205.07276},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2021dexperts,
      title={DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts}, 
      author={Alisa Liu and Maarten Sap and Ximing Lu and Swabha Swayamdipta and Chandra Bhagavatula and Noah A. Smith and Yejin Choi},
      year={2021},
      eprint={2105.03023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kirchenbauer2023watermark,
      title={A Watermark for Large Language Models}, 
      author={John Kirchenbauer and Jonas Geiping and Yuxin Wen and Jonathan Katz and Ian Miers and Tom Goldstein},
      year={2023},
      eprint={2301.10226},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{liu2024tuning,
      title={Tuning Language Models by Proxy}, 
      author={Alisa Liu and Xiaochuang Han and Yizhong Wang and Yulia Tsvetkov and Yejin Choi and Noah A. Smith},
      year={2024},
      eprint={2401.08565},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yang2023inference,
      title={Inference with Reference: Lossless Acceleration of Large Language Models}, 
      author={Nan Yang and Tao Ge and Liang Wang and Binxing Jiao and Daxin Jiang and Linjun Yang and Rangan Majumder and Furu Wei},
      year={2023},
      eprint={2304.04487},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{stern2018blockwise,
      title={Blockwise Parallel Decoding for Deep Autoregressive Models}, 
      author={Mitchell Stern and Noam Shazeer and Jakob Uszkoreit},
      year={2018},
      eprint={1811.03115},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc {gante2023assisted,
    author       = { {Joao Gante} },
    title        = { Assisted Generation: a new direction toward low-latency text generation },
    year         = 2023,
    url          = { https://huggingface.co/blog/assisted-generation },
    doi          = { 10.57967/hf/0638 },
    publisher    = { Hugging Face Blog }
}

@misc{chen2023accelerating,
      title={Accelerating Large Language Model Decoding with Speculative Sampling}, 
      author={Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
      year={2023},
      eprint={2302.01318},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{leviathan2023fast,
      title={Fast Inference from Transformers via Speculative Decoding}, 
      author={Yaniv Leviathan and Matan Kalman and Yossi Matias},
      year={2023},
      eprint={2211.17192},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{
xia2023speculative,
title={Speculative Decoding: Lossless Speedup of Autoregressive Translation},
author={Heming Xia and Tao Ge and Si-Qing Chen and Furu Wei and Zhifang Sui},
year={2023},
url={https://openreview.net/forum?id=H-VlwsYvVi}
}

@misc{hu2024inference,
      title={Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads}, 
      author={Cunchen Hu and Heyang Huang and Liangliang Xu and Xusheng Chen and Jiang Xu and Shuang Chen and Hao Feng and Chenxi Wang and Sa Wang and Yungang Bao and Ninghui Sun and Yizhou Shan},
      year={2024},
      eprint={2401.11181},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{holmes2024deepspeedfastgen,
      title={DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference}, 
      author={Connor Holmes and Masahiro Tanaka and Michael Wyatt and Ammar Ahmad Awan and Jeff Rasley and Samyam Rajbhandari and Reza Yazdani Aminabadi and Heyang Qin and Arash Bakhtiari and Lev Kurilenko and Yuxiong He},
      year={2024},
      eprint={2401.08671},
      archivePrefix={arXiv},
      primaryClass={cs.PF}
}

@misc{juravsky2024hydragen,
      title={Hydragen: High-Throughput LLM Inference with Shared Prefixes}, 
      author={Jordan Juravsky and Bradley Brown and Ryan Ehrlich and Daniel Y. Fu and Christopher Ré and Azalia Mirhoseini},
      year={2024},
      eprint={2402.05099},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kwon2023efficient,
      title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
      author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
      year={2023},
      eprint={2309.06180},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hong2024flashdecoding,
      title={FlashDecoding++: Faster Large Language Model Inference on GPUs}, 
      author={Ke Hong and Guohao Dai and Jiaming Xu and Qiuli Mao and Xiuhong Li and Jun Liu and Kangdi Chen and Yuhan Dong and Yu Wang},
      year={2024},
      eprint={2311.01282},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{yao2023react,
      title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
      author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
      year={2023},
      eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2022understanding,
      title={Towards Understanding Mixture of Experts in Deep Learning}, 
      author={Zixiang Chen and Yihe Deng and Yue Wu and Quanquan Gu and Yuanzhi Li},
      year={2022},
      eprint={2208.02813},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{fedus2022switch,
      title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity}, 
      author={William Fedus and Barret Zoph and Noam Shazeer},
      year={2022},
      eprint={2101.03961},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@online{flashdec,
  author = {Tri Dao and Daniel Haziza and Francisco Massa and Grigory Sizov},
  title = {FlashDecoding},
  year = 2023,
  url={https://crfm.stanford.edu/2023/10/12/flashdecoding.html},
  urldate = {2024-03-01}
}

@misc{cai2024medusa,
      title={Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads}, 
      author={Tianle Cai and Yuhong Li and Zhengyang Geng and Hongwu Peng and Jason D. Lee and Deming Chen and Tri Dao},
      year={2024},
      eprint={2401.10774},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hong2024orpo,
      title={ORPO: Monolithic Preference Optimization without Reference Model}, 
      author={Jiwoo Hong and Noah Lee and James Thorne},
      year={2024},
      eprint={2403.07691},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@misc{rafailov2023direct,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dao2023flashattention2,
      title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning}, 
      author={Tri Dao},
      year={2023},
      eprint={2307.08691},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{OpenAI2024,
    author       = {OpenAI},
    title        = {GPT-4o Introduction Page},
    year         = {2024},
    url          = {https://openai.com/index/hello-gpt-4o/},
    note         = {Accessed: 2024-05-29}
}

@misc{xu2024instantmesh,
      title={InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models}, 
      author={Jiale Xu and Weihao Cheng and Yiming Gao and Xintao Wang and Shenghua Gao and Ying Shan},
      year={2024},
      eprint={2404.07191},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{jiang2023motiongpt,
      title={MotionGPT: Human Motion as a Foreign Language}, 
      author={Biao Jiang and Xin Chen and Wen Liu and Jingyi Yu and Gang Yu and Tao Chen},
      year={2023},
      eprint={2306.14795},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{das2024decoderonly,
      title={A decoder-only foundation model for time-series forecasting}, 
      author={Abhimanyu Das and Weihao Kong and Rajat Sen and Yichen Zhou},
      year={2024},
      eprint={2310.10688},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ramesh2022hierarchical,
      title={Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
      author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
      year={2022},
      eprint={2204.06125},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bruce2024genie,
      title={Genie: Generative Interactive Environments}, 
      author={Jake Bruce and Michael Dennis and Ashley Edwards and Jack Parker-Holder and Yuge Shi and Edward Hughes and Matthew Lai and Aditi Mavalankar and Richie Steigerwald and Chris Apps and Yusuf Aytar and Sarah Bechtle and Feryal Behbahani and Stephanie Chan and Nicolas Heess and Lucy Gonzalez and Simon Osindero and Sherjil Ozair and Scott Reed and Jingwei Zhang and Konrad Zolna and Jeff Clune and Nando de Freitas and Satinder Singh and Tim Rocktäschel},
      year={2024},
      eprint={2402.15391},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{embodimentcollaboration2024open,
      title={Open X-Embodiment: Robotic Learning Datasets and RT-X Models}, 
      author={Embodiment Collaboration and Abby O'Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Andrey Kolobov and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Felipe Vieira Frujeri and Freek Stulp and Gaoyue Zhou and Gaurav S. Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and João Silvério and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J. Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi "Jim" Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen and Marion Lepert and Marius Memmel and Masayoshi Tomizuka and Masha Itkina and Mateo Guaman Castro and Max Spero and Maximilian Du and Michael Ahn and Michael C. Yip and Mingtong Zhang and Mingyu Ding and Minho Heo and Mohan Kumar Srirama and Mohit Sharma and Moo Jin Kim and Naoaki Kanazawa and Nicklas Hansen and Nicolas Heess and Nikhil J Joshi and Niko Suenderhauf and Ning Liu and Norman Di Palo and Nur Muhammad Mahi Shafiullah and Oier Mees and Oliver Kroemer and Osbert Bastani and Pannag R Sanketi and Patrick "Tree" Miller and Patrick Yin and Paul Wohlhart and Peng Xu and Peter David Fagan and Peter Mitrano and Pierre Sermanet and Pieter Abbeel and Priya Sundaresan and Qiuyu Chen and Quan Vuong and Rafael Rafailov and Ran Tian and Ria Doshi and Roberto Mart{'i}n-Mart{'i}n and Rohan Baijal and Rosario Scalise and Rose Hendrix and Roy Lin and Runjia Qian and Ruohan Zhang and Russell Mendonca and Rutav Shah and Ryan Hoque and Ryan Julian and Samuel Bustamante and Sean Kirmani and Sergey Levine and Shan Lin and Sherry Moore and Shikhar Bahl and Shivin Dass and Shubham Sonawani and Shuran Song and Sichun Xu and Siddhant Haldar and Siddharth Karamcheti and Simeon Adebola and Simon Guist and Soroush Nasiriany and Stefan Schaal and Stefan Welker and Stephen Tian and Subramanian Ramamoorthy and Sudeep Dasari and Suneel Belkhale and Sungjae Park and Suraj Nair and Suvir Mirchandani and Takayuki Osa and Tanmay Gupta and Tatsuya Harada and Tatsuya Matsushima and Ted Xiao and Thomas Kollar and Tianhe Yu and Tianli Ding and Todor Davchev and Tony Z. Zhao and Travis Armstrong and Trevor Darrell and Trinity Chung and Vidhi Jain and Vincent Vanhoucke and Wei Zhan and Wenxuan Zhou and Wolfram Burgard and Xi Chen and Xiangyu Chen and Xiaolong Wang and Xinghao Zhu and Xinyang Geng and Xiyuan Liu and Xu Liangwei and Xuanlin Li and Yansong Pang and Yao Lu and Yecheng Jason Ma and Yejin Kim and Yevgen Chebotar and Yifan Zhou and Yifeng Zhu and Yilin Wu and Ying Xu and Yixuan Wang and Yonatan Bisk and Yoonyoung Cho and Youngwoon Lee and Yuchen Cui and Yue Cao and Yueh-Hua Wu and Yujin Tang and Yuke Zhu and Yunchu Zhang and Yunfan Jiang and Yunshuang Li and Yunzhu Li and Yusuke Iwasawa and Yutaka Matsuo and Zehan Ma and Zhuo Xu and Zichen Jeff Cui and Zichen Zhang and Zipeng Fu and Zipeng Lin},
      year={2024},
      eprint={2310.08864},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{liu2024world,
      title={World Model on Million-Length Video And Language With Blockwise RingAttention}, 
      author={Hao Liu and Wilson Yan and Matei Zaharia and Pieter Abbeel},
      year={2024},
      eprint={2402.08268},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@misc{tang2023codi2,
      title={CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation}, 
      author={Zineng Tang and Ziyi Yang and Mahmoud Khademi and Yang Liu and Chenguang Zhu and Mohit Bansal},
      year={2023},
      eprint={2311.18775},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023},
  url={https://arxiv.org/pdf/2304.08485.pdf}
}


@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@inproceedings{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@inproceedings{lifeofbrian1979,
  title        = {Monty Python's Life of Brian},
  author       = {Terry Jones and John Goldstone and Monty Python},
  booktitle    = {Proceedings of the Monty Python Comedy Collection},
  year         = 1979,
  editor       = {Monty Python},
  organization = {HandMade Films},
  address      = {United Kingdom},
  note         = {Comedy film},
}

@misc{gu2023mamba,
      title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces}, 
      author={Albert Gu and Tri Dao},
      year={2023},
      eprint={2312.00752},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}