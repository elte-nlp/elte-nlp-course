@online{Llamacpp,
  author = {Georgi Gerganov},
  title = {llama.cpp - Inference of Meta's LLaMA model (and others) in pure C/C++},
  year = 2023,
  url = {https://github.com/ggerganov/llama.cpp},
  urldate = {2024-03-01}
}

@misc{agrawal2023sarathi,
      title={SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills}, 
      author={Amey Agrawal and Ashish Panwar and Jayashree Mohan and Nipun Kwatra and Bhargav S. Gulavani and Ramachandran Ramjee},
      year={2023},
      eprint={2308.16369},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{willard2023efficient,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sitdikov2022classifiers,
      title={Classifiers are Better Experts for Controllable Text Generation}, 
      author={Askhat Sitdikov and Nikita Balagansky and Daniil Gavrilov and Alexander Markov},
      year={2022},
      eprint={2205.07276},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2021dexperts,
      title={DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts}, 
      author={Alisa Liu and Maarten Sap and Ximing Lu and Swabha Swayamdipta and Chandra Bhagavatula and Noah A. Smith and Yejin Choi},
      year={2021},
      eprint={2105.03023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kirchenbauer2023watermark,
      title={A Watermark for Large Language Models}, 
      author={John Kirchenbauer and Jonas Geiping and Yuxin Wen and Jonathan Katz and Ian Miers and Tom Goldstein},
      year={2023},
      eprint={2301.10226},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{liu2024tuning,
      title={Tuning Language Models by Proxy}, 
      author={Alisa Liu and Xiaochuang Han and Yizhong Wang and Yulia Tsvetkov and Yejin Choi and Noah A. Smith},
      year={2024},
      eprint={2401.08565},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yang2023inference,
      title={Inference with Reference: Lossless Acceleration of Large Language Models}, 
      author={Nan Yang and Tao Ge and Liang Wang and Binxing Jiao and Daxin Jiang and Linjun Yang and Rangan Majumder and Furu Wei},
      year={2023},
      eprint={2304.04487},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{stern2018blockwise,
      title={Blockwise Parallel Decoding for Deep Autoregressive Models}, 
      author={Mitchell Stern and Noam Shazeer and Jakob Uszkoreit},
      year={2018},
      eprint={1811.03115},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc {gante2023assisted,
    author       = { {Joao Gante} },
    title        = { Assisted Generation: a new direction toward low-latency text generation },
    year         = 2023,
    url          = { https://huggingface.co/blog/assisted-generation },
    doi          = { 10.57967/hf/0638 },
    publisher    = { Hugging Face Blog }
}

@misc{chen2023accelerating,
      title={Accelerating Large Language Model Decoding with Speculative Sampling}, 
      author={Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
      year={2023},
      eprint={2302.01318},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{leviathan2023fast,
      title={Fast Inference from Transformers via Speculative Decoding}, 
      author={Yaniv Leviathan and Matan Kalman and Yossi Matias},
      year={2023},
      eprint={2211.17192},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{
xia2023speculative,
title={Speculative Decoding: Lossless Speedup of Autoregressive Translation},
author={Heming Xia and Tao Ge and Si-Qing Chen and Furu Wei and Zhifang Sui},
year={2023},
url={https://openreview.net/forum?id=H-VlwsYvVi}
}

@misc{hu2024inference,
      title={Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads}, 
      author={Cunchen Hu and Heyang Huang and Liangliang Xu and Xusheng Chen and Jiang Xu and Shuang Chen and Hao Feng and Chenxi Wang and Sa Wang and Yungang Bao and Ninghui Sun and Yizhou Shan},
      year={2024},
      eprint={2401.11181},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{holmes2024deepspeedfastgen,
      title={DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference}, 
      author={Connor Holmes and Masahiro Tanaka and Michael Wyatt and Ammar Ahmad Awan and Jeff Rasley and Samyam Rajbhandari and Reza Yazdani Aminabadi and Heyang Qin and Arash Bakhtiari and Lev Kurilenko and Yuxiong He},
      year={2024},
      eprint={2401.08671},
      archivePrefix={arXiv},
      primaryClass={cs.PF}
}

@misc{juravsky2024hydragen,
      title={Hydragen: High-Throughput LLM Inference with Shared Prefixes}, 
      author={Jordan Juravsky and Bradley Brown and Ryan Ehrlich and Daniel Y. Fu and Christopher Ré and Azalia Mirhoseini},
      year={2024},
      eprint={2402.05099},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kwon2023efficient,
      title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
      author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
      year={2023},
      eprint={2309.06180},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hong2024flashdecoding,
      title={FlashDecoding++: Faster Large Language Model Inference on GPUs}, 
      author={Ke Hong and Guohao Dai and Jiaming Xu and Qiuli Mao and Xiuhong Li and Jun Liu and Kangdi Chen and Yuhan Dong and Yu Wang},
      year={2024},
      eprint={2311.01282},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@online{flashdec,
  author = {Tri Dao and Daniel Haziza and Francisco Massa and Grigory Sizov},
  title = {FlashDecoding},
  year = 2023,
  url={https://crfm.stanford.edu/2023/10/12/flashdecoding.html},
  urldate = {2024-03-01}
}