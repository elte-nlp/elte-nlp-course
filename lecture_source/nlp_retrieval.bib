@inproceedings{dudek2023learning,
  title={Learning Sparse Lexical Representations Over Specified Vocabularies for Retrieval},
  author={Dudek, Jeffrey M and Kong, Weize and Li, Cheng and Zhang, Mingyang and Bendersky, Michael},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={3865--3869},
  year={2023}
}

@misc{kamalloo2023resourcesbrewingbeirreproducible,
      title={Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard}, 
      author={Ehsan Kamalloo and Nandan Thakur and Carlos Lassance and Xueguang Ma and Jheng-Hong Yang and Jimmy Lin},
      year={2023},
      eprint={2306.07471},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.07471}, 
}

@misc{nogueira2019documentexpansionqueryprediction,
      title={Document Expansion by Query Prediction}, 
      author={Rodrigo Nogueira and Wei Yang and Jimmy Lin and Kyunghyun Cho},
      year={2019},
      eprint={1904.08375},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1904.08375}, 
}
@misc{nogueira2020passagererankingbert,
      title={Passage Re-ranking with BERT}, 
      author={Rodrigo Nogueira and Kyunghyun Cho},
      year={2020},
      eprint={1901.04085},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1901.04085}, 
}

@misc{thakur2021beirheterogenousbenchmarkzeroshot,
      title={BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models}, 
      author={Nandan Thakur and Nils Reimers and Andreas Rücklé and Abhishek Srivastava and Iryna Gurevych},
      year={2021},
      eprint={2104.08663},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2104.08663}, 
}

@misc{zhao2020spartaefficientopendomainquestion,
      title={SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval}, 
      author={Tiancheng Zhao and Xiaopeng Lu and Kyusong Lee},
      year={2020},
      eprint={2009.13013},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13013}, 
}

@misc{santhanam2022colbertv2effectiveefficientretrieval,
      title={ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction}, 
      author={Keshav Santhanam and Omar Khattab and Jon Saad-Falcon and Christopher Potts and Matei Zaharia},
      year={2022},
      eprint={2112.01488},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2112.01488}, 
}

@misc{pradeep2021expandomonoduodesignpatterntext,
      title={The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained Sequence-to-Sequence Models}, 
      author={Ronak Pradeep and Rodrigo Nogueira and Jimmy Lin},
      year={2021},
      eprint={2101.05667},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2101.05667}, 
}

@misc{khattab2020colbertefficienteffectivepassage,
      title={ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT}, 
      author={Omar Khattab and Matei Zaharia},
      year={2020},
      eprint={2004.12832},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2004.12832}, 
}

@misc{neelakantan2022textcodeembeddingscontrastive,
      title={Text and Code Embeddings by Contrastive Pre-Training}, 
      author={Arvind Neelakantan and Tao Xu and Raul Puri and Alec Radford and Jesse Michael Han and Jerry Tworek and Qiming Yuan and Nikolas Tezak and Jong Wook Kim and Chris Hallacy and Johannes Heidecke and Pranav Shyam and Boris Power and Tyna Eloundou Nekoul and Girish Sastry and Gretchen Krueger and David Schnurr and Felipe Petroski Such and Kenny Hsu and Madeleine Thompson and Tabarak Khan and Toki Sherbakov and Joanne Jang and Peter Welinder and Lilian Weng},
      year={2022},
      eprint={2201.10005},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.10005}, 
}

@misc{ni2021sentencet5scalablesentenceencoders,
      title={Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models}, 
      author={Jianmo Ni and Gustavo Hernández Ábrego and Noah Constant and Ji Ma and Keith B. Hall and Daniel Cer and Yinfei Yang},
      year={2021},
      eprint={2108.08877},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2108.08877}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@misc{qiao2019understandingbehaviorsbertranking,
      title={Understanding the Behaviors of BERT in Ranking}, 
      author={Yifan Qiao and Chenyan Xiong and Zhenghao Liu and Zhiyuan Liu},
      year={2019},
      eprint={1904.07531},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1904.07531}, 
}

@misc{reimers2019sentencebertsentenceembeddingsusing,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10084}, 
}

@misc{humeau2020polyencoderstransformerarchitecturespretraining,
      title={Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring}, 
      author={Samuel Humeau and Kurt Shuster and Marie-Anne Lachaux and Jason Weston},
      year={2020},
      eprint={1905.01969},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.01969}, 
}