
@article{bobrow1977gus,
  title={GUS, a frame-driven dialog system},
  author={Bobrow, Daniel G and Kaplan, Ronald M and Kay, Martin and Norman, Donald A and Thompson, Henry and Winograd, Terry},
  journal={Artificial intelligence},
  volume={8},
  number={2},
  pages={155--173},
  year={1977},
  publisher={Elsevier},
  url={https://nlp.stanford.edu/acvogel/gus.pdf}
}

@article{williams2016dialog,
  title={The dialog state tracking challenge series: A review},
  author={Williams, Jason D and Raux, Antoine and Henderson, Matthew},
  journal={Dialogue \& Discourse},
  volume={7},
  number={3},
  pages={4--33},
  year={2016},
  url={https://journals.uic.edu/ojs/index.php/dad/article/download/10729/9497},
}

@inproceedings{lai2020simple,
  title={A simple but effective bert model for dialog state tracking on resource-limited systems},
  author={Lai, Tuan Manh and Tran, Quan Hung and Bui, Trung and Kihara, Daisuke},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8034--8038},
  year={2020},
  organization={IEEE},
  url={https://arxiv.org/pdf/1910.12995.pdf}
}

@article{zhong2018global,
  title={Global-locally self-attentive dialogue state tracker},
  author={Zhong, Victor and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1805.09655},
  year={2018},
  url={https://arxiv.org/pdf/1805.09655.pdf}
}

@inproceedings{nayak2017plan,
  title={To Plan or not to Plan? Discourse Planning in Slot-Value Informed Sequence to Sequence Models for Language Generation.},
  author={Nayak, Neha and Hakkani-T{\"u}r, Dilek and Walker, Marilyn A and Heck, Larry P},
  booktitle={INTERSPEECH},
  pages={3339--3343},
  year={2017},
  url={https://users.soe.ucsc.edu/~maw/papers/spd-intsp-v19.pdf}
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020},
  url={https://arxiv.org/pdf/2005.00796.pdf}
}

@article{mosig2020star,
  title={Star: A schema-guided dialog dataset for transfer learning},
  author={Mosig, Johannes EM and Mehri, Shikib and Kober, Thomas},
  journal={arXiv preprint arXiv:2010.11853},
  year={2020},
  url={https://arxiv.org/pdf/2010.11853.pdf}
}

@inproceedings{rastogi2020towards,
  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},
  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={8689--8696},
  year={2020},
  url={https://arxiv.org/pdf/1909.05855.pdf}
}

@inproceedings{lee2022sgd,
  title={SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems},
  author={Lee, Harrison and Gupta, Raghav and Rastogi, Abhinav and Cao, Yuan and Zhang, Bin and Wu, Yonghui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10938--10946},
  year={2022},
  url={https://arxiv.org/pdf/2110.06800.pdf}
}


@book{mctear2022conversational,
  title={Conversational {AI}: Dialogue systems, conversational agents, and chatbots},
  author={McTear, Michael},
  year={2022},
  publisher={Springer Nature}
}

@unpublished{jurafsky2023speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2023},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{askell2021general,
      title={A General Language Assistant as a Laboratory for Alignment}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan},
      year={2021},
      eprint={2112.00861},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021},
  url={https://arxiv.org/pdf/2102.07350.pdf}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021},
  url={https://arxiv.org/pdf/2109.01652.pdf}
}

@article{wang2022self,
  title={Self-instruct: Aligning language model with self generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022},
  url={https://arxiv.org/pdf/2212.10560.pdf}
}

@article{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={arXiv preprint arXiv:2204.07705},
  year={2022},
  url={https://arxiv.org/pdf/2204.07705.pdf}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback, 2022},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={URL https://arxiv. org/abs/2203.02155},
  volume={13},
  year={2022},
  url={https://arxiv.org/pdf/2203.02155.pdf}
}

@misc{ppo,
      title={Proximal Policy Optimization (PPO)}, 
      author={Simonini, Thomas},
      year={2022},
      url={https://huggingface.co/blog/deep-rl-ppo#the-intuition-behind-ppo},
}

@misc{xinzhe2023call,
      title={How to Use OpenAIâ€™s Chat Completion API with Python}, 
      author={Li, Xinzhe},
      year={2023},
      url={https://levelup.gitconnected.com/a-beginners-guide-to-using-the-chatgpt-api-in-python-29c57775113b},
}
@article{pashevich2021episodic,
  title={Episodic Transformer for Vision-and-Language Navigation},
  author={Pashevich, Alexander and Schmid, Cordelia and Sun, Chen},
  journal={arXiv preprint arXiv:2105.06453},
  year={2021},
  url={https://arxiv.org/abs/2105.06453},
}

@inproceedings{shridhar2020alfred,
  title={{ALFRED}: A benchmark for interpreting grounded instructions for everyday tasks},
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10740--10749},
  year={2020},
  url={https://arxiv.org/abs/1912.01734}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the {Association for Computational Linguistics}},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press}
}


@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}


@article{gao2020making,
  title={Making pre-trained language models better few-shot learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}

@inproceedings{davison2019commonsense,
  title={Commonsense knowledge mining from pretrained models},
  author={Davison, Joe and Feldman, Joshua and Rush, Alexander M},
  booktitle={{EMNLP-IJCNLP}},
  pages={1173--1178},
  year={2019}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@online{simon2021large,
  author = {Simon, Julien},
  title = {Large Language Models: A New {Moore's} Law?},
  year = {2021},
  url = {https://huggingface.co/blog/large-language-models},
  titleaddon = {Hugging Face blog post}  
}


@article{schick2020few,
  title={Few-shot text generation with pattern-exploiting training},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2012.11926},
  year={2020}
}



@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-3?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}


@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@online{openai2022aligning,
  author= {{OpenAI}},
  title = {Aligning Language Models to Follow Instructions},
  year = {2022},
  url = {https://openai.com/blog/instruction-following/},
  titleaddon = {{OpenAI} blog post}  
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Preprint},
  year={2022}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@article{wolf2019build,
  title={How to build a State-of-the-Art Conversational {AI} with Transfer Learning},
  author={Wolf, Thomas},
  titleaddon={Hugging Face blog post},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{epoch2022trendsintrainingdatasetsizes,
  title = "Trends in Training Dataset Sizes",
  author = {Pablo Villalobos and Anson Ho},
  year = 2022,
  url = {https://epochai.org/blog/trends-in-training-dataset-sizes},
  note = "Accessed: 2023-7-23"
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={arXiv preprint arXiv:2007.14062},
  year={2020},
  url={https://arxiv.org/pdf/2007.14062.pdf}
}

@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}
@misc{rubin2022learning,
      title={Learning To Retrieve Prompts for In-Context Learning}, 
      author={Ohad Rubin and Jonathan Herzig and Jonathan Berant},
      year={2022},
      eprint={2112.08633},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{weng2023prompt,
  title   = "Prompt Engineering",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2023",
  month   = "Mar",
  url     = "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
}

@misc{press2023measuring,
      title={Measuring and Narrowing the Compositionality Gap in Language Models}, 
      author={Ofir Press and Muru Zhang and Sewon Min and Ludwig Schmidt and Noah A. Smith and Mike Lewis},
      year={2023},
      eprint={2210.03350},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023selfconsistency,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.11171}
}

@article{liu2021generated,
  title={Generated knowledge prompting for commonsense reasoning},
  author={Liu, Jiacheng and Liu, Alisa and Lu, Ximing and Welleck, Sean and West, Peter and Bras, Ronan Le and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2110.08387},
  year={2021},
  url={https://arxiv.org/pdf/2110.08387.pdf}
}

@misc{yao2023tree,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.10601}
}

@misc{tree-of-thought-prompting,
    author = {Dave Hulbert},
    title = {Tree of Knowledge: ToK aka Tree of Knowledge dataset for Large Language Models LLM},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
    url= {https://github.com/dave1010/tree-of-thought-prompting}
}

@article{besta2023graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  journal={arXiv preprint arXiv:2308.09687},
  year={2023}
}

@article{lyu2023faithful,
  title={Faithful chain-ofthought reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2301.13379},
  year={2023}
}

@misc{gao2023pal,
      title={PAL: Program-aided Language Models}, 
      author={Luyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig},
      year={2023},
      eprint={2211.10435},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
zhou2023large,
title={Large Language Models are Human-Level Prompt Engineers},
author={Yongchao Zhou and Andrei Ioan Muresanu and Ziwen Han and Keiran Paster and Silviu Pitis and Harris Chan and Jimmy Ba},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=92gvk82DE-}
}
@inproceedings{alayrac2022flamingo,
  author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bi\'{n}kowski, Miko\l aj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Kar\'{e}n},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {23716--23736},
  publisher = {Curran Associates, Inc.},
  title = {Flamingo: a Visual Language Model for Few-Shot Learning},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf},
  volume = {35},
  year = {2022}
}

@article{allal2023santacoder,
  title={SantaCoder: don't reach for the stars!},
  author={Allal, Loubna Ben and Li, Raymond and Kocetkov, Denis and Mou, Chenghao and Akiki, Christopher and Ferrandis, Carlos Munoz and Muennighoff, Niklas and Mishra, Mayank and Gu, Alex and Dey, Manan and others},
  eprint={2301.03988},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020},
  url={https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
  eprint={2005.14165},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  eprint={2107.03374},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2021}
}

@misc{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  eprint={2204.02311},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2022}
}

@inproceedings{conneau-etal-2020-unsupervised,
    title = "Unsupervised Cross-lingual Representation Learning at Scale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.747",
    doi = "10.18653/v1/2020.acl-main.747",
    pages = "8440--8451"
}

@inproceedings{devlin2018bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186"
}

@inproceedings{du2022glam,
  title={{GLaM}: Efficient scaling of language models with mixture-of-experts},
  author={Du, Nan and Huang, Yanping and Dai, Andrew M and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
  booktitle={International Conference on Machine Learning},
  pages={5547--5569},
  year={2022},
  organization={PMLR},
  url={https://proceedings.mlr.press/v162/du22c.html}
}

@techreport{gpt4techreport,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2023},
  eprint={2303.08774},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@article{gunasekar2023textbooks,
  title={Textbooks Are All You Need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  eprint={2306.11644},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}


@inproceedings{hoffmann2022an,
  title={An empirical analysis of compute-optimal large language model training},
  author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katherine Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Oriol Vinyals and Jack William Rae and Laurent Sifre},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=iBBcRUlOAPR}
}

@inproceedings{instructgpt_neurips,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{joshi-etal-2020-spanbert,
    title = "{S}pan{BERT}: Improving Pre-training by Representing and Predicting Spans",
    author = "Joshi, Mandar  and
      Chen, Danqi  and
      Liu, Yinhan  and
      Weld, Daniel S.  and
      Zettlemoyer, Luke  and
      Levy, Omer",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.5",
    doi = "10.1162/tacl_a_00300",
    pages = "64--77"
}

@misc{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  eprint={2001.08361},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@inproceedings{Lan2020ALBERT,
    title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
    author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=H1eA7AEtvS}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  eprint={2305.06161},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@misc{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  eprint={1907.11692},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2019}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI},
  url = "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR},
  url={http://proceedings.mlr.press/v139/radford21a.html}
}

@misc{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  eprint={2112.11446},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2021}
}

@article{raffel-t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@misc{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  eprint={2308.12950},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@misc{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  eprint={2211.05100},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2022}
}

@misc{shazeer2020glu,
  title={Glu variants improve transformer},
  author={Shazeer, Noam},
  eprint={2002.05202},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@misc{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  eprint={1909.08053},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2019}
}

@misc{su2021roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  eprint={2104.09864},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2021}
}

@misc{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  eprint={2201.08239},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2022}
}

@misc{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  eprint={2302.13971},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@misc{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  eprint={2307.09288},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@inproceedings{wei2022finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@inproceedings{xue-etal-2021-mt5,
    title = "m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer",
    author = "Xue, Linting  and
      Constant, Noah  and
      Roberts, Adam  and
      Kale, Mihir  and
      Al-Rfou, Rami  and
      Siddhant, Aditya  and
      Barua, Aditya  and
      Raffel, Colin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.41",
    doi = "10.18653/v1/2021.naacl-main.41",
    pages = "483--498"
}

@inbook{yang2019xlnet,
    author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
    title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
    year = {2019},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
    articleno = {517},
    numpages = {11},
    url = "https://dl.acm.org/doi/pdf/10.5555/3454287.3454804"
}

@misc{zheng2023judging,
  title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  eprint={2306.05685},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@article{mialon2023augmented,
  title={Augmented language models: a survey},
  author={Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2302.07842},
  year={2023}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chang2023survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={arXiv preprint arXiv:2307.03109},
  year={2023}
}

@misc{zheng2023does,
      title={Why Does ChatGPT Fall Short in Providing Truthful Answers?}, 
      author={Shen Zheng and Jie Huang and Kevin Chen-Chuan Chang},
      year={2023},
      eprint={2304.10513},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wang2021comprehensive,
  title={A comprehensive survey and experimental comparison of graph-based approximate nearest neighbor search},
  author={Wang, Mengzhao and Xu, Xiaoliang and Yue, Qiang and Wang, Yuxiang},
  journal={arXiv preprint arXiv:2101.12631},
  year={2021}
}

@inproceedings{silpa2008optimised,
  title={Optimised KD-trees for fast image descriptor matching},
  author={Silpa-Anan, Chanop and Hartley, Richard},
  booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1--8},
  year={2008},
  organization={IEEE}
}

@article{jegou2010product,
  title={Product quantization for nearest neighbor search},
  author={Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={1},
  pages={117--128},
  year={2010},
  publisher={IEEE}
}

@article{watts1998collective,
  title={Collective dynamics of â€˜small-worldâ€™networks},
  author={Watts, Duncan J and Strogatz, Steven H},
  journal={nature},
  volume={393},
  number={6684},
  pages={440--442},
  year={1998},
  publisher={Nature Publishing Group}
}

@misc{malkov2018efficient,
      title={Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs}, 
      author={Yu. A. Malkov and D. A. Yashunin},
      year={2018},
      eprint={1603.09320},
      archivePrefix={arXiv},
      primaryClass={cs.DS}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{gao2021simcse,
  title={Simcse: Simple contrastive learning of sentence embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  journal={arXiv preprint arXiv:2104.08821},
  year={2021}
}

@article{su2022one,
  title={One embedder, any task: Instruction-finetuned text embeddings},
  author={Su, Hongjin and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A and Zettlemoyer, Luke and Yu, Tao and others},
  journal={arXiv preprint arXiv:2212.09741},
  year={2022}
}

@misc{gao2022precise,
      title={Precise Zero-Shot Dense Retrieval without Relevance Labels}, 
      author={Luyu Gao and Xueguang Ma and Jimmy Lin and Jamie Callan},
      year={2022},
      eprint={2212.10496},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle={International conference on machine learning},
  pages={3929--3938},
  year={2020},
  organization={PMLR}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}

@misc{qin2023toolllm,
      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, 
      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2307.16789},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{yang2023autogpt,
      title={Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions}, 
      author={Hui Yang and Sifu Yue and Yunzhong He},
      year={2023},
      eprint={2306.02224},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{chen2023extending,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  eprint={2306.15595},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@misc{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  eprint={1904.10509},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2019}
}

@inproceedings{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@misc{dao2023flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  eprint={2307.08691},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2023}
}

@inproceedings{ press2022train,
  title = {Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation},
  author = {Ofir Press and Noah Smith and Mike Lewis},
  booktitle = {International Conference on Learning Representations},
  year = {2022},
  url = {https://openreview.net/forum?id=R8sQPpGCv0}
}

@inproceedings{xiong-etal-2022-simple,
    title = "Simple Local Attentions Remain Competitive for Long-Context Tasks",
    author = "Xiong, Wenhan  and
      Oguz, Barlas  and
      Gupta, Anchit  and
      Chen, Xilun  and
      Liskovich, Diana  and
      Levy, Omer  and
      Yih, Scott  and
      Mehdad, Yashar",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.144",
    doi = "10.18653/v1/2022.naacl-main.144",
    pages = "1975--1986"
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  eprint={2007.14062},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@inproceedings{aghajanyan-etal-2021-intrinsic,
    title = "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning",
    author = "Aghajanyan, Armen  and
      Gupta, Sonal  and
      Zettlemoyer, Luke",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.568",
    doi = "10.18653/v1/2021.acl-long.568",
    pages = "7319--7328",
}

@inproceedings{buciluÇŽ2006model,
  title={Model compression},
  author={BuciluÇŽ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}

@inproceedings{frantar2023optq,
  title={{OPTQ}: Accurate Quantization for Generative Pre-trained Transformers},
  author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=tcbBPnfwxS}
}

@misc{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  eprint={1503.02531},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2015}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{hu2022lora,
  title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@misc{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  eprint={2001.08361},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059"
}


@inproceedings{li2018measuring,
  title={Measuring the Intrinsic Dimension of Objective Landscapes},
  author={Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=ryup8-WCW},
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597"
}

@article{liu2023gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={AI Open},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{liu-etal-2022-p,
    title = "{P}-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
    author = "Liu, Xiao  and
      Ji, Kaixuan  and
      Fu, Yicheng  and
      Tam, Weng  and
      Du, Zhengxiao  and
      Yang, Zhilin  and
      Tang, Jie",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.8",
    doi = "10.18653/v1/2022.acl-short.8",
    pages = "61--68"
}

@inproceedings{rebuffi2017adapter,
  author = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  title = {Learning Multiple Visual Domains with Residual Adapters},
  year = {2017},
  isbn = {9781510860964},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages = {506â€“516},
  numpages = {11},
  location = {Long Beach, California, USA},
  series = {NIPS'17}
}

@misc{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  eprint={1910.01108},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2019}
}

@article{schwartz2020green,
  title={Green ai},
  author={Schwartz, Roy and Dodge, Jesse and Smith, Noah A and Etzioni, Oren},
  journal={Communications of the ACM},
  volume={63},
  number={12},
  pages={54--63},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{strubell-etal-2019-energy,
    title = "Energy and Policy Considerations for Deep Learning in {NLP}",
    author = "Strubell, Emma  and
      Ganesh, Ananya  and
      McCallum, Andrew",
    editor = "Korhonen, Anna  and
      Traum, David  and
      LluÃ­s MÃ rquez",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1355",
    doi = "10.18653/v1/P19-1355",
    pages = "3645--3650"
}


@inproceedings{abadji-etal-2022-towards,
    title = "Towards a Cleaner Document-Oriented Multilingual Crawled Corpus",
    author = "Abadji, Julien  and
      Ortiz Suarez, Pedro  and
      Romary, Laurent  and
      Sagot, Benoit",
    editor = "Calzolari, Nicoletta  and
      BÃ©chet, FrÃ©dÃ©ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, HÃ©lÃ¨ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.463",
    pages = "4344--4355",
}

@online{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

@misc{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  eprint={2101.00027},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@misc{Gokaslan2019OpenWeb,
  title={OpenWebText Corpus},
  author={Aaron Gokaslan and Vanya Cohen and Ellie Pavlick and Stefanie Tellex},
  howpublished={\url{http://Skylion007.github.io/OpenWebTextCorpus}},
  year={2019}
}

@inproceedings{gururangan-etal-2018-annotation,
    title = "Annotation Artifacts in Natural Language Inference Data",
    author = "Gururangan, Suchin  and
      Swayamdipta, Swabha  and
      Levy, Omer  and
      Schwartz, Roy  and
      Bowman, Samuel  and
      Smith, Noah A.",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2017",
    doi = "10.18653/v1/N18-2017",
    pages = "107--112"
}

@inproceedings{hendrycks2021measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=d7KBjmI3GmQ}
}

@inproceedings{hoffmann2022an,
  title={An empirical analysis of compute-optimal large language model training},
  author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katherine Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Oriol Vinyals and Jack William Rae and Laurent Sifre},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=iBBcRUlOAPR}
}

@inproceedings{laurencon2022the,
  title={The BigScience {ROOTS} Corpus: A 1.6{TB} Composite Multilingual Dataset},
  author={Hugo LaurenÃ§on and Lucile Saulnier and Thomas Wang and Christopher Akiki and Albert Villanova del Moral and Teven Le Scao and Leandro Von Werra and Chenghao Mou and Eduardo Gonz{\'a}lez Ponferrada and Huu Nguyen and J{\"o}rg Frohberg and Mario {\v{S}}a{\v{s}}ko and Quentin Lhoest and Angelina McMillan-Major and G{\'e}rard Dupont and Stella Biderman and Anna Rogers and Loubna Ben allal and Francesco De Toni and Giada Pistilli and Olivier Nguyen and Somaieh Nikpoor and Maraim Masoud and Pierre Colombo and Javier de la Rosa and Paulo Villegas and Tristan Thrush and Shayne Longpre and Sebastian Nagel and Leon Weber and Manuel Romero Mu{\~n}oz and Jian Zhu and Daniel Van Strien and Zaid Alyafeai and Khalid Almubarak and Vu Minh Chien and Itziar Gonzalez-Dios and Aitor Soroa and Kyle Lo and Manan Dey and Pedro Ortiz Suarez and Aaron Gokaslan and Shamik Bose and David Ifeoluwa Adelani and Long Phan and Hieu Tran and Ian Yu and Suhas Pai and Jenny Chim and Violette Lepercq and Suzana Ilic and Margaret Mitchell and Sasha Luccioni and Yacine Jernite},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022},
  url={https://openreview.net/forum?id=UoEw6KigkUn}
}

@inproceedings{lison-tiedemann-2016-opensubtitles2016,
    title = "{O}pen{S}ubtitles2016: Extracting Large Parallel Corpora from Movie and {TV} Subtitles",
    author = {Lison, Pierre  and
      Tiedemann, J{\"o}rg},
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Grobelnik, Marko  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, Helene  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L16-1147",
    pages = "923--929"
}

@PhDThesis{	  Nemeskey:2020,
  author	= {Nemeskey, D\'avid M\'ark},
  title		= {Natural Language Processing Methods for Language
		  Modeling},
  year		= {2020},
  school	= {E\"otv\"os Lor\'and University}
}

@inproceedings{nie-etal-2020-adversarial,
    title = "Adversarial {NLI}: A New Benchmark for Natural Language Understanding",
    author = "Nie, Yixin  and
      Williams, Adina  and
      Dinan, Emily  and
      Bansal, Mohit  and
      Weston, Jason  and
      Kiela, Douwe",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.441",
    doi = "10.18653/v1/2020.acl-main.441",
    pages = "4885--4901"
}

@inproceedings{poliak-etal-2018-hypothesis,
    title = "Hypothesis Only Baselines in Natural Language Inference",
    author = "Poliak, Adam  and
      Naradowsky, Jason  and
      Haldar, Aparajita  and
      Rudinger, Rachel  and
      Van Durme, Benjamin",
    editor = "Nissim, Malvina  and
      Berant, Jonathan  and
      Lenci, Alessandro",
    booktitle = "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S18-2023",
    doi = "10.18653/v1/S18-2023",
    pages = "180--191"
}


@phdthesis{pomikalek2011removing,
  title={Removing boilerplate and duplicate content from web corpora},
  author={Pomik{\'a}lek, Jan},
  school={Masaryk university, Faculty of informatics, Brno, Czech Republic},
  year={2011}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"
}

@article{raffel-t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{rajpurkar-etal-2018-know,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2124",
    doi = "10.18653/v1/P18-2124",
    pages = "784--789"
}

@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={BIG-bench authors},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=uyTL5Bvosj}
}

@inproceedings{wang-etal-2018-glue,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    editor = "Linzen, Tal  and
      Chrupa{\l}a, Grzegorz  and
      Alishahi, Afra",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5446",
    doi = "10.18653/v1/W18-5446",
    pages = "353--355"
}

@inbook{wang-etal-2019-superglue,
author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {294},
numpages = {15}
}

@inproceedings{wei2022finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{weng2023prompt,
  title   = "Prompt Engineering",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2023",
  month   = "Mar",
  url     = "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@inproceedings{aghajanyan-etal-2021-intrinsic,
    title = "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning",
    author = "Aghajanyan, Armen  and
      Gupta, Sonal  and
      Zettlemoyer, Luke",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.568",
    doi = "10.18653/v1/2021.acl-long.568",
    pages = "7319--7328",
}

@inproceedings{buciluÇŽ2006model,
  title={Model compression},
  author={BuciluÇŽ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}

@inproceedings{frantar2023optq,
  title={{OPTQ}: Accurate Quantization for Generative Pre-trained Transformers},
  author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=tcbBPnfwxS}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mukherjee2023orca,
      title={Orca: Progressive Learning from Complex Explanation Traces of GPT-4}, 
      author={Subhabrata Mukherjee and Arindam Mitra and Ganesh Jawahar and Sahaj Agarwal and Hamid Palangi and Ahmed Awadallah},
      year={2023},
      eprint={2306.02707},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  eprint={1503.02531},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2015}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{hu2022lora,
  title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@misc{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  eprint={2001.08361},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2020}
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059"
}


@inproceedings{li2018measuring,
  title={Measuring the Intrinsic Dimension of Objective Landscapes},
  author={Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=ryup8-WCW},
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597"
}

@article{liu2023gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={AI Open},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{liu-etal-2022-p,
    title = "{P}-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
    author = "Liu, Xiao  and
      Ji, Kaixuan  and
      Fu, Yicheng  and
      Tam, Weng  and
      Du, Zhengxiao  and
      Yang, Zhilin  and
      Tang, Jie",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.8",
    doi = "10.18653/v1/2022.acl-short.8",
    pages = "61--68"
}

@inproceedings{rebuffi2017adapter,
  author = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  title = {Learning Multiple Visual Domains with Residual Adapters},
  year = {2017},
  isbn = {9781510860964},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages = {506â€“516},
  numpages = {11},
  location = {Long Beach, California, USA},
  series = {NIPS'17}
}

@misc{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  eprint={1910.01108},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  year={2019}
}

@article{schwartz2020green,
  title={Green ai},
  author={Schwartz, Roy and Dodge, Jesse and Smith, Noah A and Etzioni, Oren},
  journal={Communications of the ACM},
  volume={63},
  number={12},
  pages={54--63},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{strubell-etal-2019-energy,
    title = "Energy and Policy Considerations for Deep Learning in {NLP}",
    author = "Strubell, Emma  and
      Ganesh, Ananya  and
      McCallum, Andrew",
    editor = "Korhonen, Anna  and
      Traum, David  and
      LluÃ­s MÃ rquez",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1355",
    doi = "10.18653/v1/P19-1355",
    pages = "3645--3650"
}

@audio{hiphi2019,
  author={Barry Lam},
  title={The Illusionist},
  year=2019,
  series={HiPhi nation podcast},
  url={https://hiphination.org/season-3-episodes/s3-episode-9-the-illusionist-jun-8-2019/}
}

@Misc{santos2014,
  author = 	 {Santos, JoÃ£o Felipe},
  title = 	 {Speech signal representations},
  year = 	 {2014},
  url = {http://www.seaandsailor.com/initial_representation.html}
}

@Misc{ogorman2023,
  author = 	 {O'Gorman, Liz},
  title = 	 {Decomposing Fourier transforms â€” an introduction to
                  time-frequency decompositio},
  year = 	 {2023},
  url = {https://dibsmethodsmeetings.github.io/fourier-transforms/}
}

@unpublished{jurafsky2019speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2019},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@book{gales2008application,
  title={The application of hidden Markov models in speech recognition},
  author={Gales, Mark and Young, Steve},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@inproceedings{laureys2001assessing,
  title={Assessing segmentations: Two methods for confidence scoring automatic HMM-based word segmentations},
  author={Laureys, Tom and Demuynck, Kris and Duchateau, Jacques and Wambacq, Patrick and Bogan-Marta, Alina},
  booktitle={Proc. of the 6th International Conference on Engineering of Modern Electric Systems},
  pages={116--121},
  year={2001}
}

@article{akpudo2021cost,
  title={A cost-efficient MFCC-based fault detection and isolation technology for electromagnetic pumps},
  author={Akpudo, Ugochukwu Ejike and Hur, Jang-Wook},
  journal={Electronics},
  volume={10},
  number={4},
  pages={439},
  year={2021},
  publisher={MDPI}
}

@article{zhao1999decision,
  title={Decision tree-based state tying for acoustic modeling},
  author={Zhao, J and Zhang, X and Ganapathiraju, A and Deshmukh, N and Picone, J},
  journal={A Tutorial},
  year={1999},
  url = {https://www.cse.iitb.ac.in/~pjyothi/cs753/TiedstateHMMs.pdf}
}
@inproceedings{kipyatkova2016dnn,
  title={DNN-based acoustic modeling for Russian speech recognition using Kaldi},
  author={Kipyatkova, Irina and Karpov, Alexey},
  booktitle={Speech and Computer: 18th International Conference, SPECOM 2016, Budapest, Hungary, August 23-27, 2016, Proceedings 18},
  pages={246--253},
  year={2016},
  organization={Springer},
  url= {https://tinyurl.com/38bewvex}
}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014},
  url={https://arxiv.org/pdf/1412.5567.pdf}
}

@article{hannun2017sequence,
  title={Sequence modeling with ctc},
  author={Hannun, Awni},
  journal={Distill},
  volume={2},
  number={11},
  pages={e8},
  year={2017},
  url={https://distill.pub/2017/ctc/}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}


@misc{openai2022whisper,
        author = {{OpenAI}},
	title = {Introducing {Whisper}},
	url = {https://openai.com/research/whisper},
	abstract = {Weâ€™ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speechÂ recognition.},
	language = {en-US},
	note = {OpenAI},
	urldate = {2023-12-03},
	journal = {OpenAI Research Blog},
	year={2022},
}

@article{le2020contrastive,
  title={Contrastive representation learning: A framework and review},
  author={Le-Khac, Phuc H and Healy, Graham and Smeaton, Alan F},
  journal={Ieee Access},
  volume={8},
  pages={193907--193934},
  year={2020},
  publisher={IEEE}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@misc{zimmermann2022contrastive,
      title={Contrastive Learning Inverts the Data Generating Process}, 
      author={Roland S. Zimmermann and Yash Sharma and Steffen Schneider and Matthias Bethge and Wieland Brendel},
      year={2022},
      eprint={2102.08850},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dawid2023introduction,
      title={Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence}, 
      author={Anna Dawid and Yann LeCun},
      year={2023},
      eprint={2306.02572},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@article{dangovski2021equivariant,
  title={Equivariant contrastive learning},
  author={Dangovski, Rumen and Jing, Li and Loh, Charlotte and Han, Seungwook and Srivastava, Akash and Cheung, Brian and Agrawal, Pulkit and Solja{\v{c}}i{\'c}, Marin},
  journal={arXiv preprint arXiv:2111.00899},
  year={2021}
}

@article{su2022one,
  title={One embedder, any task: Instruction-finetuned text embeddings},
  author={Su, Hongjin and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A and Zettlemoyer, Luke and Yu, Tao and others},
  journal={arXiv preprint arXiv:2212.09741},
  year={2022}
}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{schuhmann2022laion5b,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
      }

@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@misc{mokady2021clipcap,
      title={ClipCap: CLIP Prefix for Image Captioning}, 
      author={Ron Mokady and Amir Hertz and Amit H. Bermano},
      year={2021},
      eprint={2111.09734},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{li2023decap,
  title={DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training},
  author={Li, Wei and Zhu, Linchao and Wen, Longyin and Yang, Yi},
  journal={arXiv preprint arXiv:2303.03032},
  year={2023}
}

@article{nukrai2022text,
  title={Text-only training for image captioning using noise-injected clip},
  author={Nukrai, David and Mokady, Ron and Globerson, Amir},
  journal={arXiv preprint arXiv:2211.00575},
  year={2022}
}

@misc{lee2019set,
      title={Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks}, 
      author={Juho Lee and Yoonho Lee and Jungtaek Kim and Adam R. Kosiorek and Seungjin Choi and Yee Whye Teh},
      year={2019},
      eprint={1810.00825},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}
@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume=3,
  pages={1137--1155},
  year=2003,
  url={https://bit.ly/3rkKa4M}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@article{levy2014neural,
  title={Neural word embedding as implicit matrix factorization},
  author={Levy, Omer and Goldberg, Yoav},
  journal={Advances in neural information processing systems},
  volume=27,
  pages={2177--2185},
  year=2014,
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013},
  url={https://arxiv.org/pdf/1301.3781.pdf}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume=26,
  pages={3111--3119},
  year=2013,
  url={https://bit.ly/2WxL8MT}}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014},
  url={https://nlp.stanford.edu/pubs/glove.pdf}
}

@unpublished{jurafsky2019speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2019},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{levy2015improving,
  title={Improving distributional similarity with lessons learned from word embeddings},
  author={Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  journal={Transactions of the Association for Computational Linguistics},
  volume=3,
  pages={211--225},
  year=2015,
  publisher={MIT Press},
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{heinzerling2017bpemb,
  title={BPEmb: Tokenization-free pre-trained subword embeddings in 275 languages},
  author={Heinzerling, Benjamin and Strube, Michael},
  journal={arXiv preprint arXiv:1710.02187},
  year={2017},
  url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  url={https://bit.ly/3hoXoJx}
}

@unpublished{olah2015understanding,
  title={Understanding {LSTM} networks},
  author={Olah, Christopher},
  year={2015},
  url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library},
  url={https://crl.ucsd.edu/~elman/Papers/fsit.pdf}
}


@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={1171--1179},
  year={2015},
  url={https://bit.ly/3rHrYCO}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{chorowski2015attention,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{karpathy2015unreasonable,
  title={The unreasonable effectiveness of recurrent neural networks. {B}log post},
  author={Karpathy, Andrej},
  url={http://karpathy.github.io/2015/05/21/rnn-effectiveness},
  year={2015}
  }

@article{falcon2018taming,
  title={Taming {LSTM}s. {B}log post},
  author={Falcon, William},
  url={https://bit.ly/38PFJ9T},
  year={2018}
  }

@article{minaee2019deep,
  title={Deep-sentiment: Sentiment analysis using ensemble of {CNN} and bi-{LSTM} models},
  author={Minaee, Shervin and Azimi, Elham and Abdolrashidi, AmirAli},
  journal={arXiv preprint arXiv:1904.04206},
  year={2019},
  url={https://arxiv.org/pdf/1904.04206.pdf}
}

@article{faust2018automated,
  title={Automated detection of atrial fibrillation using long short-term memory network with RR interval signals},
  author={Faust, Oliver and Shenfield, Alex and Kareem, Murtadha and San, Tan Ru and Fujita, Hamido and Acharya, U Rajendra},
  journal={Computers in biology and medicine},
  volume={102},
  pages={327--335},
  year={2018},
  publisher={Elsevier},
  url={https://bit.ly/2LdAEA0}
}

 @book{murphy2021pml,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2021,
 url = "http://mlbayes.ai"
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{choromanski2022rethinking,
      title={Rethinking Attention with Performers}, 
      author={Krzysztof Choromanski and Valerii Likhosherstov and David Dohan and Xingyou Song and Andreea Gane and Tamas Sarlos and Peter Hawkins and Jared Davis and Afroz Mohiuddin and Lukasz Kaiser and David Belanger and Lucy Colwell and Adrian Weller},
      year={2022},
      eprint={2009.14794},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{grigsby2023longrange,
      title={Long-Range Transformers for Dynamic Spatiotemporal Forecasting}, 
      author={Jake Grigsby and Zhe Wang and Nam Nguyen and Yanjun Qi},
      year={2023},
      eprint={2109.12218},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{wang2020position,
  title={What do position embeddings learn? an empirical study of pre-trained language model positional encoding},
  author={Wang, Yu-An and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2010.04903},
  year={2020}
}

@phdthesis{elbayad2020rethinking,
  title={Rethinking the Design of Sequence-to-Sequence Models for Efficient Machine Translation},
  author={Elbayad, Maha},
  year={2020},
  school={Universit{\'e} Grenoble Alpes [2020-....]}
}

@misc{sun2023retentive,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@phdthesis{luong2016neural,
  title={Neural machine translation},
  author={Luong, Minh-Thang},
  year={2016},
  school={Stanford University},
  url={https://bit.ly/3hJ1wEo}
}

@book{koopman2013introduction,
  title={An introduction to syntactic analysis and theory},
  author={Koopman, Hilda and Sportiche, Dominique and Stabler, Edward},
  year={2013},
  publisher={John Wiley \& Sons},
  url = {https://linguistics.ucla.edu/people/stabler/isat.pdf}
}

@article{nivre2013beyond,
  title = {Beyond {MaltParser}. {P}resentation},
  author = {Nivre, Joakim},
  year = {2013},
  url = {https://bit.ly/3q2jm86}
}

@inproceedings{nivre-nilsson-2005-pseudo,
    title = "Pseudo-Projective Dependency Parsing",
    author = "Nivre, Joakim  and
      Nilsson, Jens",
    booktitle = "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05)",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P05-1013",
    doi = "10.3115/1219840.1219853",
    pages = "99--106",
}

@inproceedings{huang2009bilingually,
  title={Bilingually-constrained (monolingual) shift-reduce parsing},
  author={Huang, Liang and Jiang, Wenbin and Liu, Qun},
  booktitle={Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  pages={1222--1231},
  year=2009,
  url={https://dl.acm.org/doi/10.5555/1699648.1699668}
}

@inproceedings{chen2014fast,
  title={A fast and accurate dependency parser using neural networks},
  author={Chen, Danqi and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={740--750},
  year={2014},
  url={https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf}
}

@article{dozat2016deep,
  title={Deep biaffine attention for neural dependency parsing},
  author={Dozat, Timothy and Manning, Christopher D},
  journal={arXiv preprint arXiv:1611.01734},
  year={2016},
  url={https://arxiv.org/pdf/1611.01734.pdf}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018},
  url={https://arxiv.org/pdf/1802.05365.pdf}
}

@inproceedings{akbik2018contextual,
  title={Contextual string embeddings for sequence labeling},
  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={1638--1649},
  year={2018},
  url={http://alanakbik.github.io/papers/coling2018.pdf}
}

@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}

@misc{carion2020endtoend,
      title={End-to-End Object Detection with Transformers}, 
      author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
      year={2020},
      eprint={2005.12872},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lin2021endtoend,
      title={End-to-End Human Pose and Mesh Reconstruction with Transformers}, 
      author={Kevin Lin and Lijuan Wang and Zicheng Liu},
      year={2021},
      eprint={2012.09760},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zheng2021rethinking,
      title={Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers}, 
      author={Sixiao Zheng and Jiachen Lu and Hengshuang Zhao and Xiatian Zhu and Zekun Luo and Yabiao Wang and Yanwei Fu and Jianfeng Feng and Tao Xiang and Philip H. S. Torr and Li Zhang},
      year={2021},
      eprint={2012.15840},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yu2022coca,
      title={CoCa: Contrastive Captioners are Image-Text Foundation Models}, 
      author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
      year={2022},
      eprint={2205.01917},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{oquab2023dinov2,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and TimothÃ©e Darcet and ThÃ©o Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and HervÃ© Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2023},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{caron2021emerging,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and HervÃ© JÃ©gou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu2022swin,
      title={Swin Transformer V2: Scaling Up Capacity and Resolution}, 
      author={Ze Liu and Han Hu and Yutong Lin and Zhuliang Yao and Zhenda Xie and Yixuan Wei and Jia Ning and Yue Cao and Zheng Zhang and Li Dong and Furu Wei and Baining Guo},
      year={2022},
      eprint={2111.09883},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Touvron2022DeiTIR,
  title={DeiT III: Revenge of the ViT},
  author={Hugo Touvron and Matthieu Cord and Herve Jegou},
  journal={arXiv preprint arXiv:2204.07118},
  year={2022},
}

@InProceedings{pmlr-v139-touvron21a,
  title =     {Training data-efficient image transformers &amp; distillation through attention},
  author =    {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
  booktitle = {International Conference on Machine Learning},
  pages =     {10347--10357},
  year =      {2021},
  volume =    {139},
  month =     {July}
}

@misc{yuan2021tokenstotoken,
      title={Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet}, 
      author={Li Yuan and Yunpeng Chen and Tao Wang and Weihao Yu and Yujun Shi and Zihang Jiang and Francis EH Tay and Jiashi Feng and Shuicheng Yan},
      year={2021},
      eprint={2101.11986},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017},
  url={https://arxiv.org/pdf/1706.03762.pdf}
}

@article{alammar2018illustrated,
  title={The illustrated transformer. {B}log post},
  author={Alammar, Jay},
  year={2018},
  url={http://jalammar.github.io/illustrated-transformer/}
  }

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://bit.ly/3qtMGop}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018},
  url={https://arxiv.org/abs/1810.04805}
}

@article{horev2018bert,
  title={{BERT} -- State of the Art Language Model. {B}log post},
  author={Horev, Rani},
  url={https://bit.ly/3bC6xNU},
  year={2018}
  }

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019},
  url={https://arxiv.org/pdf/1910.01108.pdf}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={arXiv preprint arXiv:2007.14062},
  year={2020},
  url={https://arxiv.org/pdf/2007.14062.pdf}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020},
  url={https://arxiv.org/pdf/2005.14165.pdf}
}

@InCollection{sep-compositionality,
	author       =	{Szab\'o, Zolt\'an Gendler},
	title        =	{{Compositionality}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	year         =	{2020},
	edition      =	{Fall 2020},
	publisher    =	{Metaphysics Research Lab, Stanford},
	url ={https://stanford.io/3nLH0UJ}
}

@article{navigli2009word,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM computing surveys (CSUR)},
  volume={41},
  number={2},
  pages={1--69},
  year={2009},
  publisher={ACM New York, NY, USA},
  url={https://bit.ly/2LwiQAP}
}

@misc{buutbogel2009fsmorph,
  title={Finite State Morphology Tutorial},
  author={Butt, Miriam and B\"ogel, Tina},
  year={2009},
  url={https://bit.ly/3sm44fx}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020},
  url={https://arxiv.org/abs/2005.00796}
}

@misc{hafner2018tfdistvae,
  author = {Hafner, Danijar},
  title = {Building Variational Auto-Encoders in TensorFlow},
  year = {2018},
  howpublished = {Blog post},
  url = {https://danijar.com/building-variational-auto-encoders-in-tensorflow/}
}


@misc{aqueel2023vae,
  author = {Anwar, Aqeel},
  title = {Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE)},
  year = {2021},
  howpublished = {Blog post},
  url = {https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2}
}

@article{doersch2016tutorial,
  title={Tutorial on variational autoencoders},
  author={Doersch, Carl},
  journal={arXiv preprint arXiv:1606.05908},
  year={2016},
  url={https://arxiv.org/pdf/1606.05908.pdf}
}

 @book{pml2Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: Advanced Topics",
 publisher = "MIT Press",
 year = 2023,
 url = "http://probml.github.io/book2"
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017},
  url={https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf}
}

@misc{askary2020intuitive,
  title={Intuitive Explanation of Straight-Through Estimators with PyTorch Implementation},
  author={Askary, Hassan},
  year={2020},
  publisher={Blog post},
  url={https://hassanaskary.medium.com/intuitive-explanation-of-straight-through-estimators-with-pytorch-implementation-71d99d25d9d0}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR},
  url={https://arxiv.org/abs/2102.12092}
}

@inproceedings{li2023trocr,
  title={Trocr: Transformer-based optical character recognition with pre-trained models},
  author={Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={11},
  pages={13094--13102},
  year={2023}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023},
  url={https://arxiv.org/pdf/2304.08485.pdf}
}

@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023},
  url={https://arxiv.org/pdf/2310.03744.pdf}
}

@misc{zhang2023texttoimage,
      title={Text-to-image Diffusion Models in Generative AI: A Survey}, 
      author={Chenshuang Zhang and Chaoning Zhang and Mengchun Zhang and In So Kweon},
      year={2023},
      eprint={2303.07909},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2023adding,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{mou2023t2iadapter,
      title={T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models}, 
      author={Chong Mou and Xintao Wang and Liangbin Xie and Yanze Wu and Jian Zhang and Zhongang Qi and Ying Shan and Xiaohu Qie},
      year={2023},
      eprint={2302.08453},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{song2022denoising,
      title={Denoising Diffusion Implicit Models}, 
      author={Jiaming Song and Chenlin Meng and Stefano Ermon},
      year={2022},
      eprint={2010.02502},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@misc{saharia2022photorealistic,
      title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding}, 
      author={Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and S. Sara Mahdavi and Rapha Gontijo Lopes and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi},
      year={2022},
      eprint={2205.11487},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yu2022scaling,
      title={Scaling Autoregressive Models for Content-Rich Text-to-Image Generation}, 
      author={Jiahui Yu and Yuanzhong Xu and Jing Yu Koh and Thang Luong and Gunjan Baid and Zirui Wang and Vijay Vasudevan and Alexander Ku and Yinfei Yang and Burcu Karagol Ayan and Ben Hutchinson and Wei Han and Zarana Parekh and Xin Li and Han Zhang and Jason Baldridge and Yonghui Wu},
      year={2022},
      eprint={2206.10789},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{BetkerImprovingIG,
  title={Improving Image Generation with Better Captions},
  author={James Betker and Gabriel Goh and Li Jing and â€  TimBrooks and Jianfeng Wang and Linjie Li and â€  LongOuyang and â€  JuntangZhuang and â€  JoyceLee and â€  YufeiGuo and â€  WesamManassra and â€  PrafullaDhariwal and â€  CaseyChu and â€  YunxinJiao and Aditya Ramesh},
  url={https://api.semanticscholar.org/CorpusID:264403242}
}

@misc{pernias2023wuerstchen,
      title={Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models}, 
      author={Pablo Pernias and Dominic Rampas and Mats L. Richter and Christopher J. Pal and Marc Aubreville},
      year={2023},
      eprint={2306.00637},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@misc{ho2022classifierfree,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{foret2021sharpnessaware,
      title={Sharpness-Aware Minimization for Efficiently Improving Generalization}, 
      author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
      year={2021},
      eprint={2010.01412},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{luo2023latent,
      title={Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference}, 
      author={Simian Luo and Yiqin Tan and Longbo Huang and Jian Li and Hang Zhao},
      year={2023},
      eprint={2310.04378},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{luo2023lcmlora,
      title={LCM-LoRA: A Universal Stable-Diffusion Acceleration Module}, 
      author={Simian Luo and Yiqin Tan and Suraj Patil and Daniel Gu and Patrick von Platen and ApolinÃ¡rio Passos and Longbo Huang and Jian Li and Hang Zhao},
      year={2023},
      eprint={2311.05556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{hu2022lora,
  title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@misc{gu2023mixofshow,
      title={Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models}, 
      author={Yuchao Gu and Xintao Wang and Jay Zhangjie Wu and Yujun Shi and Yunpeng Chen and Zihan Fan and Wuyou Xiao and Rui Zhao and Shuning Chang and Weijia Wu and Yixiao Ge and Ying Shan and Mike Zheng Shou},
      year={2023},
      eprint={2305.18292},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gal2022image,
      title={An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion}, 
      author={Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit H. Bermano and Gal Chechik and Daniel Cohen-Or},
      year={2022},
      eprint={2208.01618},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{rombach2022highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@misc{nichol2022glide,
      title={GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models}, 
      author={Alex Nichol and Prafulla Dhariwal and Aditya Ramesh and Pranav Shyam and Pamela Mishkin and Bob McGrew and Ilya Sutskever and Mark Chen},
      year={2022},
      eprint={2112.10741},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{karras2022elucidating,
      title={Elucidating the Design Space of Diffusion-Based Generative Models}, 
      author={Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
      year={2022},
      eprint={2206.00364},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lu2023dpmsolver,
      title={DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models}, 
      author={Cheng Lu and Yuhao Zhou and Fan Bao and Jianfei Chen and Chongxuan Li and Jun Zhu},
      year={2023},
      eprint={2211.01095},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ho2020denoising,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{child2019generating,
      title={Generating Long Sequences with Sparse Transformers}, 
      author={Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
      year={2019},
      eprint={1904.10509},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ramesh2021zeroshot,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2019controllable,
      title={Controllable Text-to-Image Generation}, 
      author={Bowen Li and Xiaojuan Qi and Thomas Lukasiewicz and Philip H. S. Torr},
      year={2019},
      eprint={1909.07083},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{reed2016generative,
      title={Generative Adversarial Text to Image Synthesis}, 
      author={Scott Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and Bernt Schiele and Honglak Lee},
      year={2016},
      eprint={1605.05396},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{mansimov2016generating,
      title={Generating Images from Captions with Attention}, 
      author={Elman Mansimov and Emilio Parisotto and Jimmy Lei Ba and Ruslan Salakhutdinov},
      year={2016},
      eprint={1511.02793},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gregor2015draw,
      title={DRAW: A Recurrent Neural Network For Image Generation}, 
      author={Karol Gregor and Ivo Danihelka and Alex Graves and Danilo Jimenez Rezende and Daan Wierstra},
      year={2015},
      eprint={1502.04623},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{le2020contrastive,
  title={Contrastive representation learning: A framework and review},
  author={Le-Khac, Phuc H and Healy, Graham and Smeaton, Alan F},
  journal={Ieee Access},
  volume={8},
  pages={193907--193934},
  year={2020},
  publisher={IEEE}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@misc{zimmermann2022contrastive,
      title={Contrastive Learning Inverts the Data Generating Process}, 
      author={Roland S. Zimmermann and Yash Sharma and Steffen Schneider and Matthias Bethge and Wieland Brendel},
      year={2022},
      eprint={2102.08850},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dawid2023introduction,
      title={Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence}, 
      author={Anna Dawid and Yann LeCun},
      year={2023},
      eprint={2306.02572},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@article{dangovski2021equivariant,
  title={Equivariant contrastive learning},
  author={Dangovski, Rumen and Jing, Li and Loh, Charlotte and Han, Seungwook and Srivastava, Akash and Cheung, Brian and Agrawal, Pulkit and Solja{\v{c}}i{\'c}, Marin},
  journal={arXiv preprint arXiv:2111.00899},
  year={2021}
}

@article{su2022one,
  title={One embedder, any task: Instruction-finetuned text embeddings},
  author={Su, Hongjin and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A and Zettlemoyer, Luke and Yu, Tao and others},
  journal={arXiv preprint arXiv:2212.09741},
  year={2022}
}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{schuhmann2022laion5b,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
      }

@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@misc{mokady2021clipcap,
      title={ClipCap: CLIP Prefix for Image Captioning}, 
      author={Ron Mokady and Amir Hertz and Amit H. Bermano},
      year={2021},
      eprint={2111.09734},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{li2023decap,
  title={DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training},
  author={Li, Wei and Zhu, Linchao and Wen, Longyin and Yang, Yi},
  journal={arXiv preprint arXiv:2303.03032},
  year={2023}
}

@article{nukrai2022text,
  title={Text-only training for image captioning using noise-injected clip},
  author={Nukrai, David and Mokady, Ron and Globerson, Amir},
  journal={arXiv preprint arXiv:2211.00575},
  year={2022}
}

@misc{lee2019set,
      title={Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks}, 
      author={Juho Lee and Yoonho Lee and Jungtaek Kim and Adam R. Kosiorek and Seungjin Choi and Yee Whye Teh},
      year={2019},
      eprint={1810.00825},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}
@inproceedings{dietterich2000ensemble,
  title={Ensemble methods in machine learning},
  author={Dietterich, Thomas G},
  booktitle={International workshop on multiple classifier systems},
  pages={1--15},
  year={2000},
  organization={Springer}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@misc{shazeer2017outrageously,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{belcak2023fast,
      title={Fast Feedforward Networks}, 
      author={Peter Belcak and Roger Wattenhofer},
      year={2023},
      eprint={2308.14711},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2022image,
      title={Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks}, 
      author={Wenhui Wang and Hangbo Bao and Li Dong and Johan Bjorck and Zhiliang Peng and Qiang Liu and Kriti Aggarwal and Owais Khan Mohammed and Saksham Singhal and Subhojit Som and Furu Wei},
      year={2022},
      eprint={2208.10442},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2022understanding,
      title={Towards Understanding Mixture of Experts in Deep Learning}, 
      author={Zixiang Chen and Yihe Deng and Yue Wu and Quanquan Gu and Yuanzhi Li},
      year={2022},
      eprint={2208.02813},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{anonymous2023mole,
title={Mo{LE}: Mixture of Lo{RA} Experts},
author={Anonymous},
booktitle={Submitted to The Twelfth International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=uWvKBCYh4S},
note={under review}
}

@misc{wu2023pituning,
      title={$\pi$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation}, 
      author={Chengyue Wu and Teng Wang and Yixiao Ge and Zeyu Lu and Ruisong Zhou and Ying Shan and Ping Luo},
      year={2023},
      eprint={2304.14381},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zadouri2023pushing,
      title={Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning}, 
      author={Ted Zadouri and Ahmet ÃœstÃ¼n and Arash Ahmadian and Beyza ErmiÅŸ and Acyr Locatelli and Sara Hooker},
      year={2023},
      eprint={2309.05444},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2023moelora,
      title={MOELoRA: An MOE-based Parameter Efficient Fine-Tuning Method for Multi-task Medical Applications}, 
      author={Qidong Liu and Xian Wu and Xiangyu Zhao and Yuanshao Zhu and Derong Xu and Feng Tian and Yefeng Zheng},
      year={2023},
      eprint={2310.18339},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{fedus2022switch,
      title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity}, 
      author={William Fedus and Barret Zoph and Noam Shazeer},
      year={2022},
      eprint={2101.03961},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{belcak2023exponentially,
      title={Exponentially Faster Language Modelling}, 
      author={Peter Belcak and Roger Wattenhofer},
      year={2023},
      eprint={2311.10770},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{pashevich2021episodic,
  title={Episodic Transformer for Vision-and-Language Navigation},
  author={Pashevich, Alexander and Schmid, Cordelia and Sun, Chen},
  journal={arXiv preprint arXiv:2105.06453},
  year={2021},
  url={https://arxiv.org/abs/2105.06453},
}

@inproceedings{shridhar2020alfred,
  title={{ALFRED}: A benchmark for interpreting grounded instructions for everyday tasks},
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10740--10749},
  year={2020},
  url={https://arxiv.org/abs/1912.01734}
}

@article{brohan2022rt,
  title={{RT-1}: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022},
  url={https://arxiv.org/pdf/2212.06817.pdf}
}

@article{driess2023palm,
  title={Pa{LM-E}: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{brohan2023rt,
  title={{RT}-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023},
  url={https://arxiv.org/pdf/2307.15818.pdf}
}

@article{arora2016latent,
    title = "A Latent Variable Model Approach to {PMI}-based Word Embeddings",
    author = "Arora, Sanjeev  and
      Li, Yuanzhi  and
      Liang, Yingyu  and
      Ma, Tengyu  and
      Risteski, Andrej",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q16-1028",
    doi = "10.1162/tacl_a_00106",
    pages = "385--399"
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume=3,
  pages={1137--1155},
  year=2003,
  url={https://bit.ly/3rkKa4M}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@article{levy2014neural,
  title={Neural word embedding as implicit matrix factorization},
  author={Levy, Omer and Goldberg, Yoav},
  journal={Advances in neural information processing systems},
  volume=27,
  pages={2177--2185},
  year=2014,
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013},
  url={https://arxiv.org/pdf/1301.3781.pdf}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume=26,
  pages={3111--3119},
  year=2013,
  url={https://bit.ly/2WxL8MT}
}

@inproceedings{mikolov2013linguistic,
    title = "Linguistic Regularities in Continuous Space Word Representations",
    author = "Mikolov, Tomas  and
      Yih, Wen-tau  and
      Zweig, Geoffrey",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1090",
    pages = "746--751",
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014},
  url={https://nlp.stanford.edu/pubs/glove.pdf}
}

@unpublished{jurafsky2019speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2019},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{levy2015improving,
  title={Improving distributional similarity with lessons learned from word embeddings},
  author={Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  journal={Transactions of the Association for Computational Linguistics},
  volume=3,
  pages={211--225},
  year=2015,
  publisher={MIT Press},
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{heinzerling2017bpemb,
  title={BPEmb: Tokenization-free pre-trained subword embeddings in 275 languages},
  author={Heinzerling, Benjamin and Strube, Michael},
  journal={arXiv preprint arXiv:1710.02187},
  year={2017},
  url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  url={https://bit.ly/3hoXoJx}
}

@unpublished{olah2015understanding,
  title={Understanding {LSTM} networks},
  author={Olah, Christopher},
  year={2015},
  url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library},
  url={https://crl.ucsd.edu/~elman/Papers/fsit.pdf}
}


@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={1171--1179},
  year={2015},
  url={https://bit.ly/3rHrYCO}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{karpathy2015unreasonable,
  title={The unreasonable effectiveness of recurrent neural networks. {B}log post},
  author={Karpathy, Andrej},
  url={http://karpathy.github.io/2015/05/21/rnn-effectiveness},
  year={2015}
  }

@article{falcon2018taming,
  title={Taming {LSTM}s. {B}log post},
  author={Falcon, William},
  url={https://bit.ly/38PFJ9T},
  year={2018}
  }

@article{minaee2019deep,
  title={Deep-sentiment: Sentiment analysis using ensemble of {CNN} and bi-{LSTM} models},
  author={Minaee, Shervin and Azimi, Elham and Abdolrashidi, AmirAli},
  journal={arXiv preprint arXiv:1904.04206},
  year={2019},
  url={https://arxiv.org/pdf/1904.04206.pdf}
}

@article{faust2018automated,
  title={Automated detection of atrial fibrillation using long short-term memory network with RR interval signals},
  author={Faust, Oliver and Shenfield, Alex and Kareem, Murtadha and San, Tan Ru and Fujita, Hamido and Acharya, U Rajendra},
  journal={Computers in biology and medicine},
  volume={102},
  pages={327--335},
  year={2018},
  publisher={Elsevier},
  url={https://bit.ly/2LdAEA0}
}

 @book{murphy2021pml,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2021,
 url = "http://mlbayes.ai"
}

@phdthesis{luong2016neural,
  title={Neural machine translation},
  author={Luong, Minh-Thang},
  year={2016},
  school={Stanford University},
  url={https://bit.ly/3hJ1wEo}
}

@book{koopman2013introduction,
  title={An introduction to syntactic analysis and theory},
  author={Koopman, Hilda and Sportiche, Dominique and Stabler, Edward},
  year={2013},
  publisher={John Wiley \& Sons},
  url = {https://linguistics.ucla.edu/people/stabler/isat.pdf}
}

@article{nivre2013beyond,
  title = {Beyond {MaltParser}. {P}resentation},
  author = {Nivre, Joakim},
  year = {2013},
  url = {https://bit.ly/3q2jm86}
}

@inproceedings{nivre-nilsson-2005-pseudo,
    title = "Pseudo-Projective Dependency Parsing",
    author = "Nivre, Joakim  and
      Nilsson, Jens",
    booktitle = "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05)",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P05-1013",
    doi = "10.3115/1219840.1219853",
    pages = "99--106",
}

@inproceedings{huang2009bilingually,
  title={Bilingually-constrained (monolingual) shift-reduce parsing},
  author={Huang, Liang and Jiang, Wenbin and Liu, Qun},
  booktitle={Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  pages={1222--1231},
  year=2009,
  url={https://dl.acm.org/doi/10.5555/1699648.1699668}
}

@inproceedings{chen2014fast,
  title={A fast and accurate dependency parser using neural networks},
  author={Chen, Danqi and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={740--750},
  year={2014},
  url={https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf}
}

@article{dozat2016deep,
  title={Deep biaffine attention for neural dependency parsing},
  author={Dozat, Timothy and Manning, Christopher D},
  journal={arXiv preprint arXiv:1611.01734},
  year={2016},
  url={https://arxiv.org/pdf/1611.01734.pdf}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018},
  url={https://arxiv.org/pdf/1802.05365.pdf}
}

@inproceedings{akbik2018contextual,
  title={Contextual string embeddings for sequence labeling},
  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={1638--1649},
  year={2018},
  url={http://alanakbik.github.io/papers/coling2018.pdf}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017},
  url={https://arxiv.org/pdf/1706.03762.pdf}
}

@article{alammar2018illustrated,
  title={The illustrated transformer. {B}log post},
  author={Alammar, Jay},
  year={2018},
  url={http://jalammar.github.io/illustrated-transformer/}
  }

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://bit.ly/3qtMGop}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018},
  url={https://arxiv.org/abs/1810.04805}
}

@article{horev2018bert,
  title={{BERT} -- State of the Art Language Model. {B}log post},
  author={Horev, Rani},
  url={https://bit.ly/3bC6xNU},
  year={2018}
  }

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019},
  url={https://arxiv.org/pdf/1910.01108.pdf}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={arXiv preprint arXiv:2007.14062},
  year={2020},
  url={https://arxiv.org/pdf/2007.14062.pdf}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020},
  url={https://arxiv.org/pdf/2005.14165.pdf}
}

@InCollection{sep-compositionality,
	author       =	{Szab\'o, Zolt\'an Gendler},
	title        =	{{Compositionality}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	year         =	{2020},
	edition      =	{Fall 2020},
	publisher    =	{Metaphysics Research Lab, Stanford},
	url ={https://stanford.io/3nLH0UJ}
}

@article{navigli2009word,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM computing surveys (CSUR)},
  volume={41},
  number={2},
  pages={1--69},
  year={2009},
  publisher={ACM New York, NY, USA},
  url={https://bit.ly/2LwiQAP}
}

@misc{buutbogel2009fsmorph,
  title={Finite State Morphology Tutorial},
  author={Butt, Miriam and B\"ogel, Tina},
  year={2009},
  url={https://bit.ly/3sm44fx}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020},
  url={https://arxiv.org/abs/2005.00796}
}

@inproceedings{kudo-2018-subword,
    title = "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates",
    author = "Kudo, Taku",
    booktitle = "Proceedings of the 56th Annual Meeting of the ACL (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "ACL",
    url = "https://aclanthology.org/P18-1007",
    doi = "10.18653/v1/P18-1007",
    pages = "66--75"
}

@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@inproceedings{provilkov-etal-2020-bpe,
    title = "{BPE}-Dropout: Simple and Effective Subword Regularization",
    author = "Provilkov, Ivan  and
      Emelianenko, Dmitrii  and
      Voita, Elena",
    booktitle = "Proceedings of the 58th Annual Meeting of the ACL",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://aclanthology.org/2020.acl-main.170",
    doi = "10.18653/v1/2020.acl-main.170",
    pages = "1882--1892"
}

@article{arora2016latent,
    title = "A Latent Variable Model Approach to {PMI}-based Word Embeddings",
    author = "Arora, Sanjeev  and
      Li, Yuanzhi  and
      Liang, Yingyu  and
      Ma, Tengyu  and
      Risteski, Andrej",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q16-1028",
    doi = "10.1162/tacl_a_00106",
    pages = "385--399"
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume=3,
  pages={1137--1155},
  year=2003,
  url={https://bit.ly/3rkKa4M}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@article{levy2014neural,
  title={Neural word embedding as implicit matrix factorization},
  author={Levy, Omer and Goldberg, Yoav},
  journal={Advances in neural information processing systems},
  volume=27,
  pages={2177--2185},
  year=2014,
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013},
  url={https://arxiv.org/pdf/1301.3781.pdf}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume=26,
  pages={3111--3119},
  year=2013,
  url={https://bit.ly/2WxL8MT}
}

@inproceedings{mikolov2013linguistic,
    title = "Linguistic Regularities in Continuous Space Word Representations",
    author = "Mikolov, Tomas  and
      Yih, Wen-tau  and
      Zweig, Geoffrey",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1090",
    pages = "746--751",
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014},
  url={https://nlp.stanford.edu/pubs/glove.pdf}
}

@unpublished{jurafsky2019speech,
  title={Speech and language processing (3rd ed. draft)},
  author={Jurafsky, Daniel and Martin, James H},
  year={2019},
  url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{levy2015improving,
  title={Improving distributional similarity with lessons learned from word embeddings},
  author={Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  journal={Transactions of the Association for Computational Linguistics},
  volume=3,
  pages={211--225},
  year=2015,
  publisher={MIT Press},
  url={https://www.aclweb.org/anthology/Q15-1016.pdf}
}

@article{heinzerling2017bpemb,
  title={BPEmb: Tokenization-free pre-trained subword embeddings in 275 languages},
  author={Heinzerling, Benjamin and Strube, Michael},
  journal={arXiv preprint arXiv:1710.02187},
  year={2017},
  url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/1049.pdf}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  url={https://bit.ly/3hoXoJx}
}

@unpublished{olah2015understanding,
  title={Understanding {LSTM} networks},
  author={Olah, Christopher},
  year={2015},
  url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library},
  url={https://crl.ucsd.edu/~elman/Papers/fsit.pdf}
}


@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={1171--1179},
  year={2015},
  url={https://bit.ly/3rHrYCO}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{karpathy2015unreasonable,
  title={The unreasonable effectiveness of recurrent neural networks. {B}log post},
  author={Karpathy, Andrej},
  url={http://karpathy.github.io/2015/05/21/rnn-effectiveness},
  year={2015}
  }

@article{falcon2018taming,
  title={Taming {LSTM}s. {B}log post},
  author={Falcon, William},
  url={https://bit.ly/38PFJ9T},
  year={2018}
  }

@article{minaee2019deep,
  title={Deep-sentiment: Sentiment analysis using ensemble of {CNN} and bi-{LSTM} models},
  author={Minaee, Shervin and Azimi, Elham and Abdolrashidi, AmirAli},
  journal={arXiv preprint arXiv:1904.04206},
  year={2019},
  url={https://arxiv.org/pdf/1904.04206.pdf}
}

@article{faust2018automated,
  title={Automated detection of atrial fibrillation using long short-term memory network with RR interval signals},
  author={Faust, Oliver and Shenfield, Alex and Kareem, Murtadha and San, Tan Ru and Fujita, Hamido and Acharya, U Rajendra},
  journal={Computers in biology and medicine},
  volume={102},
  pages={327--335},
  year={2018},
  publisher={Elsevier},
  url={https://bit.ly/2LdAEA0}
}

 @book{murphy2021pml,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2021,
 url = "http://mlbayes.ai"
}

@phdthesis{luong2016neural,
  title={Neural machine translation},
  author={Luong, Minh-Thang},
  year={2016},
  school={Stanford University},
  url={https://bit.ly/3hJ1wEo}
}

@book{koopman2013introduction,
  title={An introduction to syntactic analysis and theory},
  author={Koopman, Hilda and Sportiche, Dominique and Stabler, Edward},
  year={2013},
  publisher={John Wiley \& Sons},
  url = {https://linguistics.ucla.edu/people/stabler/isat.pdf}
}

@article{nivre2013beyond,
  title = {Beyond {MaltParser}. {P}resentation},
  author = {Nivre, Joakim},
  year = {2013},
  url = {https://bit.ly/3q2jm86}
}

@inproceedings{nivre-nilsson-2005-pseudo,
    title = "Pseudo-Projective Dependency Parsing",
    author = "Nivre, Joakim  and
      Nilsson, Jens",
    booktitle = "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05)",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P05-1013",
    doi = "10.3115/1219840.1219853",
    pages = "99--106",
}

@inproceedings{huang2009bilingually,
  title={Bilingually-constrained (monolingual) shift-reduce parsing},
  author={Huang, Liang and Jiang, Wenbin and Liu, Qun},
  booktitle={Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  pages={1222--1231},
  year=2009,
  url={https://dl.acm.org/doi/10.5555/1699648.1699668}
}

@inproceedings{chen2014fast,
  title={A fast and accurate dependency parser using neural networks},
  author={Chen, Danqi and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={740--750},
  year={2014},
  url={https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf}
}

@article{dozat2016deep,
  title={Deep biaffine attention for neural dependency parsing},
  author={Dozat, Timothy and Manning, Christopher D},
  journal={arXiv preprint arXiv:1611.01734},
  year={2016},
  url={https://arxiv.org/pdf/1611.01734.pdf}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018},
  url={https://arxiv.org/pdf/1802.05365.pdf}
}

@inproceedings{akbik2018contextual,
  title={Contextual string embeddings for sequence labeling},
  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={1638--1649},
  year={2018},
  url={http://alanakbik.github.io/papers/coling2018.pdf}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017},
  url={https://arxiv.org/pdf/1706.03762.pdf}
}

@article{alammar2018illustrated,
  title={The illustrated transformer. {B}log post},
  author={Alammar, Jay},
  year={2018},
  url={http://jalammar.github.io/illustrated-transformer/}
  }

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://bit.ly/3qtMGop}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018},
  url={https://arxiv.org/abs/1810.04805}
}

@article{horev2018bert,
  title={{BERT} -- State of the Art Language Model. {B}log post},
  author={Horev, Rani},
  url={https://bit.ly/3bC6xNU},
  year={2018}
  }

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019},
  url={https://arxiv.org/pdf/1910.01108.pdf}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={arXiv preprint arXiv:2007.14062},
  year={2020},
  url={https://arxiv.org/pdf/2007.14062.pdf}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020},
  url={https://arxiv.org/pdf/2005.14165.pdf}
}

@InCollection{sep-compositionality,
	author       =	{Szab\'o, Zolt\'an Gendler},
	title        =	{{Compositionality}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	year         =	{2020},
	edition      =	{Fall 2020},
	publisher    =	{Metaphysics Research Lab, Stanford},
	url ={https://stanford.io/3nLH0UJ}
}

@article{navigli2009word,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM computing surveys (CSUR)},
  volume={41},
  number={2},
  pages={1--69},
  year={2009},
  publisher={ACM New York, NY, USA},
  url={https://bit.ly/2LwiQAP}
}

@misc{buutbogel2009fsmorph,
  title={Finite State Morphology Tutorial},
  author={Butt, Miriam and B\"ogel, Tina},
  year={2009},
  url={https://bit.ly/3sm44fx}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020},
  url={https://arxiv.org/abs/2005.00796}
}

@inproceedings{kudo-2018-subword,
    title = "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates",
    author = "Kudo, Taku",
    booktitle = "Proceedings of the 56th Annual Meeting of the ACL (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "ACL",
    url = "https://aclanthology.org/P18-1007",
    doi = "10.18653/v1/P18-1007",
    pages = "66--75"
}

@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@inproceedings{provilkov-etal-2020-bpe,
    title = "{BPE}-Dropout: Simple and Effective Subword Regularization",
    author = "Provilkov, Ivan  and
      Emelianenko, Dmitrii  and
      Voita, Elena",
    booktitle = "Proceedings of the 58th Annual Meeting of the ACL",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://aclanthology.org/2020.acl-main.170",
    doi = "10.18653/v1/2020.acl-main.170",
    pages = "1882--1892"
}
