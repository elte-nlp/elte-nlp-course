@misc{sasazawa2023textretrievalmultistagereranking,
      title={Text Retrieval with Multi-Stage Re-Ranking Models}, 
      author={Yuichi Sasazawa and Kenichi Yokote and Osamu Imaichi and Yasuhiro Sogawa},
      year={2023},
      eprint={2311.07994},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2311.07994}, 
}

@misc{kamalloo2023resourcesbrewingbeirreproducible,
      title={Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard}, 
      author={Ehsan Kamalloo and Nandan Thakur and Carlos Lassance and Xueguang Ma and Jheng-Hong Yang and Jimmy Lin},
      year={2023},
      eprint={2306.07471},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.07471}, 
}

@misc{nogueira2020passagererankingbert,
      title={Passage Re-ranking with BERT}, 
      author={Rodrigo Nogueira and Kyunghyun Cho},
      year={2020},
      eprint={1901.04085},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1901.04085}, 
}

@Inbook{Paaß2023,
author="Paa{\ss}, Gerhard
and Giesselbach, Sven",
title="Foundation Models for Text Generation",
bookTitle="Foundation Models for Natural Language Processing: Pre-trained Language Models Integrating Media",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="227--311",
abstract="This chapter discusses Foundation Models for Text Generation. This includes systems for Document Retrieval, which accept a query and return an ordered list of text documents from a document collection, often evaluating the similarity of embeddings to retrieve relevant text passages. Question Answering systems are given a natural language question and must provide an answer, usually in natural language. Machine Translation models take a text in one language and translate it into another language. Text Summarization systems receive a long document and generate a short summary covering the most important contents of the document. Text Generation models use an autoregressive Language Model to generate a longer story, usually starting from an initial text input. Dialog systems have the task of conducting a dialog with a human partner, typically not limited to a specific topic.",
isbn="978-3-031-23190-2",
doi="10.1007/978-3-031-23190-2_6",
url="https://doi.org/10.1007/978-3-031-23190-2_6"
}

@misc{pradeep2021expandomonoduodesignpatterntext,
      title={The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained Sequence-to-Sequence Models}, 
      author={Ronak Pradeep and Rodrigo Nogueira and Jimmy Lin},
      year={2021},
      eprint={2101.05667},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2101.05667}, 
}

@misc{neelakantan2022textcodeembeddingscontrastive,
      title={Text and Code Embeddings by Contrastive Pre-Training}, 
      author={Arvind Neelakantan and Tao Xu and Raul Puri and Alec Radford and Jesse Michael Han and Jerry Tworek and Qiming Yuan and Nikolas Tezak and Jong Wook Kim and Chris Hallacy and Johannes Heidecke and Pranav Shyam and Boris Power and Tyna Eloundou Nekoul and Girish Sastry and Gretchen Krueger and David Schnurr and Felipe Petroski Such and Kenny Hsu and Madeleine Thompson and Tabarak Khan and Toki Sherbakov and Joanne Jang and Peter Welinder and Lilian Weng},
      year={2022},
      eprint={2201.10005},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.10005}, 
}

@misc{ni2021sentencet5scalablesentenceencoders,
      title={Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models}, 
      author={Jianmo Ni and Gustavo Hernández Ábrego and Noah Constant and Ji Ma and Keith B. Hall and Daniel Cer and Yinfei Yang},
      year={2021},
      eprint={2108.08877},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2108.08877}, 
}

@article{wang2021comprehensive,
  title={A comprehensive survey and experimental comparison of graph-based approximate nearest neighbor search},
  author={Wang, Mengzhao and Xu, Xiaoliang and Yue, Qiang and Wang, Yuxiang},
  journal={arXiv preprint arXiv:2101.12631},
  year={2021}
}

@inproceedings{silpa2008optimised,
  title={Optimised KD-trees for fast image descriptor matching},
  author={Silpa-Anan, Chanop and Hartley, Richard},
  booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1--8},
  year={2008},
  organization={IEEE}
}


@article{watts1998collective,
  title={Collective dynamics of ‘small-world’networks},
  author={Watts, Duncan J and Strogatz, Steven H},
  journal={nature},
  volume={393},
  number={6684},
  pages={440--442},
  year={1998},
  publisher={Nature Publishing Group}
}

@misc{malkov2018efficient,
      title={Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs}, 
      author={Yu. A. Malkov and D. A. Yashunin},
      year={2018},
      eprint={1603.09320},
      archivePrefix={arXiv},
      primaryClass={cs.DS}
}

@article{jegou2010product,
  title={Product quantization for nearest neighbor search},
  author={Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={1},
  pages={117--128},
  year={2010},
  publisher={IEEE}
}

@misc{thakur2021beirheterogenousbenchmarkzeroshot,
      title={BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models}, 
      author={Nandan Thakur and Nils Reimers and Andreas Rücklé and Abhishek Srivastava and Iryna Gurevych},
      year={2021},
      eprint={2104.08663},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2104.08663}, 
}

@misc{khattab2020colbertefficienteffectivepassage,
      title={ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT}, 
      author={Omar Khattab and Matei Zaharia},
      year={2020},
      eprint={2004.12832},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2004.12832}, 
}

@misc{santhanam2022colbertv2effectiveefficientretrieval,
      title={ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction}, 
      author={Keshav Santhanam and Omar Khattab and Jon Saad-Falcon and Christopher Potts and Matei Zaharia},
      year={2022},
      eprint={2112.01488},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2112.01488}, 
}

@misc{nogueira2019documentexpansionqueryprediction,
      title={Document Expansion by Query Prediction}, 
      author={Rodrigo Nogueira and Wei Yang and Jimmy Lin and Kyunghyun Cho},
      year={2019},
      eprint={1904.08375},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1904.08375}, 
}

@misc{zhao2020spartaefficientopendomainquestion,
      title={SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval}, 
      author={Tiancheng Zhao and Xiaopeng Lu and Kyusong Lee},
      year={2020},
      eprint={2009.13013},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13013}, 
}

@misc{formal2021spladesparselexicalexpansion,
      title={SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking}, 
      author={Thibault Formal and Benjamin Piwowarski and Stéphane Clinchant},
      year={2021},
      eprint={2107.05720},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2107.05720}, 
}

@inproceedings{dudek2023learning,
  title={Learning Sparse Lexical Representations Over Specified Vocabularies for Retrieval},
  author={Dudek, Jeffrey M and Kong, Weize and Li, Cheng and Zhang, Mingyang and Bendersky, Michael},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={3865--3869},
  year={2023}
}
